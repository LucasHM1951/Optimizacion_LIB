{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coeficiente de Arrastre con GPLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib \n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from gplearn.functions import make_function\n",
    "from gplearn.fitness import make_fitness\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.utils.random import check_random_state\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import graphviz\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargando datos\n",
    "\n",
    "# importacion de DF\n",
    "file_path = 'D:\\\\CODES\\\\LIB_SR\\\\Dataset_coeficientes\\\\df_cdrag_25.txt'\n",
    "df_cdrag_25 = pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "file_path = 'D:\\\\CODES\\\\LIB_SR\\\\Dataset_coeficientes\\\\df_cdrag_53.txt'\n",
    "df_cdrag_53 = pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "file_path = 'D:\\\\CODES\\\\LIB_SR\\\\Dataset_coeficientes\\\\df_cdrag_74.txt'\n",
    "df_cdrag_74 = pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "file_path = 'D:\\\\CODES\\\\LIB_SR\\\\Dataset_coeficientes\\\\df_cdrag_102.txt'\n",
    "df_cdrag_102 = pd.read_csv(file_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiendo conjuntos de train y test\n",
    "\n",
    "# definiendo conjunto de train\n",
    "df_cdrag_train = pd.concat([df_cdrag_25, df_cdrag_74], ignore_index=True)\n",
    "\n",
    "# separando entre x e y\n",
    "y_train = df_cdrag_train.drop(columns=['Current','K','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido','n_celda','Rem','colIndex'])\n",
    "X_train = df_cdrag_train.drop(columns=['Current','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido',\n",
    "                                    'n_celda','colIndex','cdrag'])\n",
    "\n",
    "\n",
    "# definiendo conjunto de test\n",
    "\n",
    "y_test = df_cdrag_53.drop(columns=['Current','K','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido','n_celda','Rem','colIndex'])\n",
    "X_test = df_cdrag_53.drop(columns=['Current','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido',\n",
    "                                    'n_celda','colIndex','cdrag'])\n",
    "\n",
    "y_train = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento: incluyendo coeficientes de Rafael"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creando funciones auxiliares\n",
    "\n",
    "# S ^ (-0.6)\n",
    "def pot1(x1):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(x1 > 0, np.power(x1, -0.6), 0)\n",
    "    return result\n",
    "\n",
    "pot1_fn = make_function(function=pot1, \n",
    "                        name='pot1', \n",
    "                        arity=1)\n",
    "\n",
    "# 5*Re ^ (-0.23)\n",
    "def pot2(x1):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(x1 > 0, 5*np.power(x1, -0.23), 0)\n",
    "    return result\n",
    "\n",
    "pot2_fn = make_function(function=pot2, \n",
    "                        name='pot2', \n",
    "                        arity=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(expression):\n",
    "\n",
    "    # Reemplazar funciones específicas con sus representaciones matemáticas\n",
    "    expression = re.sub(r\"add\\(([^,]+), ([^\\)]+)\\)\", r\"(\\1 + \\2)\", expression)\n",
    "    expression = re.sub(r\"sub\\(([^,]+), ([^\\)]+)\\)\", r\"(\\1 - \\2)\", expression)\n",
    "    expression = re.sub(r\"mul\\(([^,]+), ([^\\)]+)\\)\", r\"(\\1 * \\2)\", expression)\n",
    "    expression = re.sub(r\"div\\(([^,]+), ([^\\)]+)\\)\", r\"(\\1 / \\2)\", expression)\n",
    "    expression = re.sub(r\"pow\\(([^,]+), ([^\\)]+)\\)\", r\"\\1 ** \\2\", expression)\n",
    "    \n",
    "    # Reemplazar la función pot1\n",
    "    expression = re.sub(r\"pot1\\((X\\d)\\)\", r\"\\1 ** (-0.6)\", expression)\n",
    "    # Reemplazar la función pot2\n",
    "    expression = re.sub(r\"pot2\\((X\\d)\\)\", r\"5 * \\1 ** (-0.23)\", expression)\n",
    "    \n",
    "    # Reemplazar variables (ajustar según el modelo)\n",
    "    expression = expression.replace(\"X0\", \"S\")\n",
    "    expression = expression.replace(\"X1\", \"Re\")\n",
    "    \n",
    "    return expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    13.80      4.44235e+07        5        0.0727931        0.0695565     12.12m\n",
      "   1     9.11      3.59451e+07        5        0.0723137        0.0738714      8.17m\n",
      "   2     6.64          25901.6        5        0.0720671        0.0760905     10.96m\n",
      "   3     6.11          12859.9        9        0.0698535        0.0740827      8.44m\n",
      "   4     6.26          37314.4        5        0.0718866        0.0777156      9.97m\n",
      "   5     5.32          22445.9        8        0.0717459        0.0728612      6.35m\n",
      "   6     5.20          23145.1        5        0.0717727        0.0787408      7.15m\n",
      "   7     5.17      1.83698e+07        5         0.071877         0.077802      6.56m\n",
      "   8     5.18          22152.1        5        0.0718211        0.0783049      6.57m\n",
      "   9     5.14          18232.1        5        0.0717828          0.07865      5.33m\n",
      "  10     5.22          42739.5        5        0.0718997        0.0775975      5.02m\n",
      "  11     5.13          22609.9        5         0.071828         0.078243      4.66m\n",
      "  12     5.16          55303.3        5        0.0718547        0.0780023      4.74m\n",
      "  13     5.17          25828.5        5        0.0717182        0.0792307      4.03m\n",
      "  14     5.18          15773.8        5        0.0718548        0.0780013      2.82m\n",
      "  15     5.16          6790.06        5        0.0719297        0.0773271      2.28m\n",
      "  16     5.15            12737        5        0.0717301        0.0791237      1.20m\n",
      "  17     5.17           164907        5        0.0717074        0.0793286     56.58s\n",
      "  18     5.16          18921.5        5        0.0717211        0.0792053     27.51s\n",
      "  19     5.23          20854.5        5        0.0718771         0.077801      0.00s\n"
     ]
    }
   ],
   "source": [
    "# entrenando modelo \n",
    "\n",
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.01, \n",
    "                        random_state=123,\n",
    "                        function_set=['add', 'sub', 'mul', 'div', 'sqrt', 'log',pot1_fn,pot2_fn])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "#print(\"Expresión:\", expression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(5 * Re ** (-0.23) + S ** (-0.6))'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite(expression.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en los datos de prueba\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparar con modelo de Rafael\n",
    "\n",
    "def cdrag(S, Re):\n",
    "    return S**(-0.6) + 5*Re**(-0.23)\n",
    "\n",
    "def cdrag_gp(S, Re):\n",
    "    return S**(-0.6) + 5*Re**(-0.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 cdrag original: 0.8904926780136748, R^2 cdrag GPLearn: 0.8904926780136748 \n",
      "MSE cdrag original: 0.011588230963563853, MSE cdrag GPLearn: 0.011588230963563853 \n",
      "MAE cdrag original: 0.07580331737181549, MAE cdrag GPLearn: 0.07580331737181549 \n",
      "MAPE cdrag original: 0.03744829246296146, MAPE cdrag GPLearn: 0.03744829246296146 \n"
     ]
    }
   ],
   "source": [
    "# Calcular cdrag_pred y cdrag_gp_pred en vectores separados\n",
    "cdrag_pred = X_test.apply(lambda row: cdrag(row['K'], row['Rem']), axis=1).values\n",
    "cdrag_gp_pred = X_test.apply(lambda row: cdrag_gp(row['K'], row['Rem']), axis=1).values\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag\n",
    "r2_cdrag = r2_score(y_test['cdrag'], cdrag_pred)\n",
    "mse_cdrag = mean_squared_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag\n",
    "mae_cdrag = mean_absolute_error(y_test['cdrag'], cdrag_pred)\n",
    "mape_cdrag = mean_absolute_percentage_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag_gp\n",
    "r2_cdrag_gp = r2_score(y_test['cdrag'], cdrag_gp_pred)\n",
    "mse_cdrag_gp = mean_squared_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag_gp\n",
    "mae_cdrag_gp = mean_absolute_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "mape_cdrag_gp = mean_absolute_percentage_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "#  Mostrar Metricas \n",
    "\n",
    "print(f\"R^2 cdrag original: {r2_cdrag}, R^2 cdrag GPLearn: {r2_cdrag_gp} \")\n",
    "print(f\"MSE cdrag original: {mse_cdrag}, MSE cdrag GPLearn: {mse_cdrag_gp} \")\n",
    "print(f\"MAE cdrag original: {mae_cdrag}, MAE cdrag GPLearn: {mae_cdrag_gp} \")\n",
    "print(f\"MAPE cdrag original: {mape_cdrag*100}*100, MAPE cdrag GPLearn: {mape_cdrag_gp*100}*100 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba 2: Separacion entre laminar y turbulento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdrag_train = pd.concat([df_cdrag_25, df_cdrag_74], ignore_index=True)\n",
    "\n",
    "# separando entre desplazamiento laminar y turbulento\n",
    "df_cdrag_train_lam = df_cdrag_train[df_cdrag_train['Rem'] <= 2000]\n",
    "df_cdrag_train_turb = df_cdrag_train[df_cdrag_train['Rem'] > 2000]\n",
    "\n",
    "y_train_lam = df_cdrag_train_lam.drop(columns=['Current','K','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido','n_celda','Rem','colIndex'])\n",
    "X_train_lam = df_cdrag_train_lam.drop(columns=['Current','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido',\n",
    "                                    'n_celda','colIndex','cdrag'])\n",
    "\n",
    "y_train_turb = df_cdrag_train_turb.drop(columns=['Current','K','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido','n_celda','Rem','colIndex'])\n",
    "X_train_turb = df_cdrag_train_turb.drop(columns=['Current','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido',\n",
    "                                    'n_celda','colIndex','cdrag'])\n",
    "\n",
    "test_lam = df_cdrag_53[df_cdrag_53['Rem'] <= 2000]\n",
    "test_turb = df_cdrag_53[df_cdrag_53['Rem'] > 2000]\n",
    "\n",
    "# definiendo conjunto de test\n",
    "\n",
    "y_test_lam = test_lam.drop(columns=['Current','K','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido','n_celda','Rem','colIndex'])\n",
    "X_test_lam = test_lam.drop(columns=['Current','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido',\n",
    "                                    'n_celda','colIndex','cdrag'])\n",
    "\n",
    "y_test_turb = test_turb.drop(columns=['Current','K','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido','n_celda','Rem','colIndex'])\n",
    "X_test_turb = test_turb.drop(columns=['Current','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido',\n",
    "                                    'n_celda','colIndex','cdrag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S ^ (-0.6)\n",
    "def pot1(x1):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(x1 > 0, np.power(x1, -0.6), 0)\n",
    "    return result\n",
    "\n",
    "pot1_fn = make_function(function=pot1, \n",
    "                        name='pot1', \n",
    "                        arity=1)\n",
    "\n",
    "# 5*Re ^ (-0.23)\n",
    "def pot2(x1):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(x1 > 0, 5*np.power(x1, -0.23), 0)\n",
    "    return result\n",
    "\n",
    "pot2_fn = make_function(function=pot2, \n",
    "                        name='pot2', \n",
    "                        arity=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    19.46      1.16325e+11       14        0.0989867         0.097607      9.94m\n",
      "   1    11.90      3.47286e+06       25         0.098282          0.10394      5.99m\n",
      "   2    10.16      1.99623e+06        9        0.0980644        0.0956614      6.94m\n",
      "   3     9.37      1.76432e+09        8        0.0961371        0.0935922      6.71m\n",
      "   4     7.70          11995.3       10          0.09412        0.0958618      5.18m\n",
      "   5     5.28      2.56837e+06       12        0.0967676        0.0973654      5.82m\n",
      "   6     5.26           265602        5         0.098622         0.113828      4.71m\n",
      "   7     5.24          3651.69        6         0.096651        0.0977687      5.83m\n",
      "   8     5.24          13647.6        4        0.0969893        0.0892327      4.91m\n",
      "   9     5.23          5050.37        4        0.0960181         0.097961      3.31m\n",
      "  10     5.23           863410        4        0.0953797         0.103698      2.85m\n",
      "  11     5.12          6854.65        4        0.0948652         0.108321      2.93m\n",
      "  12     4.81       7.5301e+09        4        0.0944604         0.111959      2.65m\n",
      "  13     4.32          9002.22        4        0.0939956         0.116136      2.13m\n",
      "  14     4.28      1.03491e+06        4        0.0945034         0.111572      1.91m\n",
      "  15     4.22      1.55576e+09        4        0.0943248         0.113178      1.13m\n",
      "  16     4.16      2.31482e+06        4        0.0943714         0.112758      1.01m\n",
      "  17     4.25          6778.33        4        0.0944862         0.111727     55.37s\n",
      "  18     4.24           876867        4        0.0941669         0.114597     46.34s\n",
      "  19     4.22      1.99237e+06        4        0.0946659         0.110112     52.88s\n",
      "  20     4.23           248928        4        0.0946512         0.110244     30.95s\n",
      "  21     4.17          15109.2        4        0.0943103         0.113308     23.96s\n",
      "  22     4.25          9819.05       43        0.0913711        0.0958376     16.10s\n",
      "  23     4.21             9994        4        0.0942617         0.113745      7.59s\n",
      "  24     4.21            99178        4        0.0943005         0.113396      0.00s\n",
      "Expresión: add(pot1(X0), 0.922)\n",
      "MSE: 0.020890382189918164\n",
      "R^2: 0.8003793812261198\n"
     ]
    }
   ],
   "source": [
    "# entrenando modelo laminar\n",
    "\n",
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                           generations=25, \n",
    "                           stopping_criteria=0.01,\n",
    "                           p_crossover=0.7, \n",
    "                           p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, \n",
    "                           p_point_mutation=0.1,\n",
    "                           max_samples=0.9, \n",
    "                           verbose=1,\n",
    "                           parsimony_coefficient=0.01, \n",
    "                           random_state=123,\n",
    "                           function_set=['add', 'sub', 'mul', 'div',pot1_fn,pot2_fn],\n",
    "                           const_range=(-10, 10))\n",
    "\n",
    "model.fit(X_train_lam, y_train_lam)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)\n",
    "\n",
    "# Predecir en los datos de prueba\n",
    "y_pred = model.predict(X_test_lam)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test_lam, y_pred)\n",
    "r2 = r2_score(y_test_lam, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    19.46      8.02502e+12       13        0.0642244        0.0631852     26.53m\n",
      "   1    11.50      5.34598e+07        5        0.0638259        0.0667703     27.34m\n",
      "   2     9.58      4.75667e+07        5        0.0635333        0.0694023     28.93m\n",
      "   3     6.43      4.82039e+07        8        0.0634863        0.0698258     23.54m\n",
      "   4     5.83          70092.2        5        0.0635609        0.0691547     25.87m\n",
      "   5     5.26      6.08778e+07        5         0.063477        0.0699095     13.39m\n",
      "   6     5.26        3.352e+06        5        0.0635552        0.0692055     12.44m\n",
      "   7     5.24          24680.8        5        0.0634513          0.07014      7.98m\n",
      "   8     5.24           136728        5        0.0634564        0.0700944      8.97m\n",
      "   9     5.24          34785.9        5          0.06352        0.0695224      8.63m\n",
      "  10     5.24      2.45341e+07        5        0.0634337        0.0702984      9.41m\n",
      "  11     5.18            49400        5        0.0634812         0.069871      6.48m\n",
      "  12     5.22      5.76699e+11        5        0.0635265        0.0694642      4.97m\n",
      "  13     5.27          75176.1        5        0.0635423        0.0693215      3.97m\n",
      "  14     5.26      2.40753e+07        5        0.0634774        0.0699057      3.50m\n",
      "  15     5.22      1.65705e+11        5        0.0634853        0.0698341      3.66m\n",
      "  16     5.15      2.54865e+07        5        0.0635249         0.069478      5.16m\n",
      "  17     5.25          42945.4        5        0.0634798        0.0698837      8.67m\n",
      "  18     5.22      2.46009e+07        5        0.0635736        0.0690405      2.93m\n",
      "  19     5.23      4.73444e+07        5        0.0635869        0.0689202      3.33m\n",
      "  20     5.19      5.08272e+06        5        0.0634941        0.0697552      1.81m\n",
      "  21     5.17           110104        5         0.063456        0.0700977      1.23m\n",
      "  22     5.23          65190.5        5        0.0634468        0.0701806     55.88s\n",
      "  23     5.21          62464.2        5        0.0635077        0.0696328     34.58s\n",
      "  24     5.19      1.25528e+06        5        0.0634498        0.0701536      0.00s\n",
      "Expresión: add(pot1(X0), pot2(X1))\n",
      "MSE: 0.008782091087103561\n",
      "R^2: 0.887412821263162\n"
     ]
    }
   ],
   "source": [
    "# entrenando modelo turbulento\n",
    "\n",
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                           generations=25, \n",
    "                           stopping_criteria=0.01,\n",
    "                           p_crossover=0.7, \n",
    "                           p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, \n",
    "                           p_point_mutation=0.1,\n",
    "                           max_samples=0.9, \n",
    "                           verbose=1,\n",
    "                           parsimony_coefficient=0.01, \n",
    "                           random_state=123,\n",
    "                           function_set=['add', 'sub', 'mul', 'div',pot1_fn,pot2_fn],\n",
    "                           const_range=(-10, 10))\n",
    "\n",
    "model.fit(X_train_turb, y_train_turb)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)\n",
    "\n",
    "# Predecir en los datos de prueba\n",
    "y_pred = model.predict(X_test_turb)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test_turb, y_pred)\n",
    "r2 = r2_score(y_test_turb, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste automatico de Exponencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pot(x1, const):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (const >= -1) & (const < 0)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(con1 & con2, np.power(x1,const), 0)\n",
    "    return result\n",
    "\n",
    "pot= make_function(function=pot, name='pot', arity=2)\n",
    "\n",
    "# A * x**B\n",
    "def pot2(x1):\n",
    "    con1 = x1 > 0\n",
    "    # con2 = (B >= -0.24) & (B <= -0.22)\n",
    "    # con3 = (A >=4.9) & (A <=5.1)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(con1  , 5 *np.power(x1,-0.23), 0)\n",
    "    return result\n",
    "\n",
    "pot2= make_function(function=pot2, name='pot2', arity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_9276\\2036374849.py:5: RuntimeWarning: overflow encountered in power\n",
      "  result = np.where(con1 & con2, np.power(x1,const), 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    27.82      5.19856e+12       14         0.119096         0.119238     38.36m\n",
      "   1    15.19      4.99107e+09        6        0.0755688        0.0714117     25.62m\n",
      "   2    14.27      3.69476e+07        6        0.0750084        0.0764555     23.72m\n",
      "   3    10.62      1.86747e+07       14        0.0728228        0.0721428     13.91m\n",
      "   4     8.56      1.33538e+11        6         0.072321        0.0766594     13.39m\n",
      "   5     6.04          16224.3        6        0.0722672         0.077143      8.90m\n",
      "   6     5.84      1.00035e+07        6        0.0721768         0.077957      7.79m\n",
      "   7     6.30          30283.6        6        0.0721093        0.0785644      7.74m\n",
      "   8     6.25          12617.2        6        0.0718201        0.0811672      5.08m\n",
      "   9     6.22          37501.5        6        0.0721354          0.07833      4.51m\n",
      "  10     6.28          46276.7        8        0.0719365        0.0737697      3.89m\n",
      "  11     6.16      1.85982e+07        6        0.0720783        0.0788438      4.84m\n",
      "  12     6.26          80988.7        6        0.0720774        0.0788517      3.62m\n",
      "  13     6.27           145452        6        0.0720114        0.0767114      3.71m\n",
      "  14     6.17      4.84665e+07        6        0.0720229        0.0766084      3.12m\n",
      "  15     6.34      4.09395e+08        6        0.0719545        0.0772239      4.00m\n",
      "  16     6.15          58481.9        6        0.0720288        0.0765553      2.11m\n",
      "  17     6.19      3.67298e+07        6        0.0717504        0.0790604     58.17s\n",
      "  18     6.17          83415.5        6        0.0719152        0.0775779     27.75s\n",
      "  19     6.21      1.32013e+08        6        0.0718982         0.077731      0.00s\n",
      "Expresión: add(pot(X0, -0.606), pot2(X1))\n"
     ]
    }
   ],
   "source": [
    "# entrenando modelo \n",
    "\n",
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.01, \n",
    "                        random_state=42,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot, pot2])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01146079397831767\n",
      "R^2: 0.8916969414616678\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdrag(S, Re):\n",
    "    return S**(-0.6) + 5*Re**(-0.23)\n",
    "\n",
    "def cdrag_gp(S, Re):\n",
    "    return S**(-0.606) + 5*Re**(-0.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 cdrag original: 0.8904926780136748, R^2 cdrag GPLearn: 0.8917492597780703 \n",
      "MSE cdrag original: 0.011588230963563853, MSE cdrag GPLearn: 0.011455257574695527 \n",
      "MAE cdrag original: 0.07580331737181549, MAE cdrag GPLearn: 0.075295920219909 \n",
      "MAPE cdrag original: 3.7448292462961463*100, MAPE cdrag GPLearn: 3.7237039210106486*100 \n"
     ]
    }
   ],
   "source": [
    "# Calcular cdrag_pred y cdrag_gp_pred en vectores separados\n",
    "cdrag_pred = X_test.apply(lambda row: cdrag(row['K'], row['Rem']), axis=1).values\n",
    "cdrag_gp_pred = X_test.apply(lambda row: cdrag_gp(row['K'], row['Rem']), axis=1).values\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag\n",
    "r2_cdrag = r2_score(y_test['cdrag'], cdrag_pred)\n",
    "mse_cdrag = mean_squared_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag\n",
    "mae_cdrag = mean_absolute_error(y_test['cdrag'], cdrag_pred)\n",
    "mape_cdrag = mean_absolute_percentage_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag_gp\n",
    "r2_cdrag_gp = r2_score(y_test['cdrag'], cdrag_gp_pred)\n",
    "mse_cdrag_gp = mean_squared_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag_gp\n",
    "mae_cdrag_gp = mean_absolute_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "mape_cdrag_gp = mean_absolute_percentage_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "#  Mostrar Metricas \n",
    "\n",
    "print(f\"R^2 cdrag original: {r2_cdrag}, R^2 cdrag GPLearn: {r2_cdrag_gp} \")\n",
    "print(f\"MSE cdrag original: {mse_cdrag}, MSE cdrag GPLearn: {mse_cdrag_gp} \")\n",
    "print(f\"MAE cdrag original: {mae_cdrag}, MAE cdrag GPLearn: {mae_cdrag_gp} \")\n",
    "print(f\"MAPE cdrag original: {mape_cdrag*100}*100, MAPE cdrag GPLearn: {mape_cdrag_gp*100}*100 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste Automatico de constantes V1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pot(x1, const):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (const >= -1) & (const < 0)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(con1 & con2, np.power(x1,const), 0)\n",
    "    return result\n",
    "\n",
    "pot= make_function(function=pot, name='pot', arity=2)\n",
    "\n",
    "# A * x**B\n",
    "def pot2(x1):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B >= -1) & (B <= 0)\n",
    "    # con3 = (A >=4.9) & (A <=5.1)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(con1  & con2, 5 *np.power(x1,-0.2), 0)\n",
    "    return result\n",
    "\n",
    "pot2= make_function(function=pot2, name='pot2', arity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste automatico de constantes V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(expression):\n",
    "\n",
    "    # Reemplazar funciones específicas con sus representaciones matemáticas\n",
    "    expression = re.sub(r\"add\\(([^,]+), ([^\\)]+)\\)\", r\"(\\1 + \\2)\", expression)\n",
    "    expression = re.sub(r\"sub\\(([^,]+), ([^\\)]+)\\)\", r\"(\\1 - \\2)\", expression)\n",
    "    expression = re.sub(r\"mul\\(([^,]+), ([^\\)]+)\\)\", r\"(\\1 * \\2)\", expression)\n",
    "    expression = re.sub(r\"div\\(([^,]+), ([^\\)]+)\\)\", r\"(\\1 / \\2)\", expression)\n",
    "    #expression = re.sub(r\"pow\\(([^,]+), ([^\\)]+)\\)\", r\"\\1 ** \\2\", expression)\n",
    "    \n",
    "    # Reemplazar la función pot\n",
    "    expression = re.sub(r\"pot\\((X\\d)\\)\", r\"\\1 ** (-0.6)\", expression)\n",
    "    # Reemplazar la función pot2\n",
    "    #expression = re.sub(r\"pot2\\((X\\d)\\)\", r\"5 * \\1 ** (-0.23)\", expression)\n",
    "    \n",
    "    # Reemplazar variables (ajustar según el modelo)\n",
    "    expression = expression.replace(\"X0\", \"S\")\n",
    "    expression = expression.replace(\"X1\", \"Re\")\n",
    "    \n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A* x ^ B\n",
    "\n",
    "def pot(x1, A, B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B >= -1) & (B < 0)\n",
    "    con3 = A >= 1\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(con1 & con2 & con3, A*np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot_fn= make_function(function=pot, name='pot', arity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_2232\\1152348812.py:8: RuntimeWarning: overflow encountered in power\n",
      "  result = np.where(con1 & con2 & con3, A*np.power(x1,B), 0)\n",
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_2232\\1152348812.py:8: RuntimeWarning: overflow encountered in multiply\n",
      "  result = np.where(con1 & con2 & con3, A*np.power(x1,B), 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    90.51          1179.24       10         0.235563          0.24473     63.57m\n",
      "   1    18.37          270.561       12         0.235133         0.248594     15.97m\n",
      "   2    11.64          256.708       13         0.235097         0.248922      9.23m\n",
      "   3     7.61          273.857       13         0.234758         0.251969      9.07m\n",
      "   4     2.79          135.077        6         0.234767         0.251887      3.32m\n",
      "   5     1.89          145.019        1         0.234883         0.250843      2.59m\n",
      "   6     1.68           122.97        1         0.234159         0.257363      2.67m\n",
      "   7     1.56          113.227        1         0.234534         0.253993      1.85m\n",
      "   8     1.72              121        1         0.234586          0.25352      2.13m\n",
      "   9     1.79          126.542        1         0.234487         0.254411      1.72m\n",
      "  10     1.54          112.799        1         0.234258         0.256473      1.53m\n",
      "  11     1.66          122.773        1         0.234233         0.249218      1.33m\n",
      "  12     1.63          106.628        1          0.23386         0.252577      1.13m\n",
      "  13     1.57          122.437        1          0.23366         0.254375     59.09s\n",
      "  14     1.73          142.956        1         0.233175         0.258746     49.99s\n",
      "  15     1.64          132.562        1         0.233373         0.256964     39.14s\n",
      "  16     1.68          103.947        1          0.23347         0.256086     29.94s\n",
      "  17     1.61          128.141        1         0.233042          0.25994     26.44s\n",
      "  18     1.89          113.385        1         0.233524         0.255603     16.76s\n",
      "  19     1.70          123.745        1         0.233679         0.254205      0.00s\n",
      "Expresión: 1.771\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.01, \n",
    "                        random_state=0,\n",
    "                        function_set=['add',pot_fn])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste Automatico de Constantes V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pot(x1, const):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (const >= -1) & (const < 0)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(con1 & con2, np.power(x1,const), 0)\n",
    "    return result\n",
    "\n",
    "pot= make_function(function=pot, name='pot', arity=2)\n",
    "\n",
    "# A * x**B\n",
    "def pot2(x1,A,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B >= -1) & (B < 0)\n",
    "    con3 = (A >=2) & (A <=8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(con1  , A *np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot2= make_function(function=pot2, name='pot2', arity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_2232\\565715426.py:16: RuntimeWarning: overflow encountered in power\n",
      "  result = np.where(con1  , A *np.power(x1,B), 0)\n",
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_2232\\565715426.py:5: RuntimeWarning: overflow encountered in power\n",
      "  result = np.where(con1 & con2, np.power(x1,const), 0)\n",
      "d:\\env\\lib\\site-packages\\gplearn\\functions.py:46: RuntimeWarning: invalid value encountered in multiply\n",
      "  return self.function(*args)\n",
      "d:\\env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:573: RuntimeWarning: invalid value encountered in multiply\n",
      "  avg = avg_as_array = np.multiply(a, wgt,\n",
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_2232\\565715426.py:16: RuntimeWarning: overflow encountered in multiply\n",
      "  result = np.where(con1  , A *np.power(x1,B), 0)\n",
      "d:\\env\\lib\\site-packages\\gplearn\\functions.py:127: RuntimeWarning: overflow encountered in divide\n",
      "  return np.where(np.abs(x2) > 0.001, np.divide(x1, x2), 1.)\n",
      "d:\\env\\lib\\site-packages\\gplearn\\functions.py:46: RuntimeWarning: overflow encountered in multiply\n",
      "  return self.function(*args)\n",
      "d:\\env\\lib\\site-packages\\gplearn\\functions.py:46: RuntimeWarning: invalid value encountered in subtract\n",
      "  return self.function(*args)\n",
      "d:\\env\\lib\\site-packages\\gplearn\\functions.py:46: RuntimeWarning: invalid value encountered in add\n",
      "  return self.function(*args)\n",
      "d:\\env\\lib\\site-packages\\numpy\\_core\\_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "d:\\env\\lib\\site-packages\\gplearn\\functions.py:46: RuntimeWarning: overflow encountered in add\n",
      "  return self.function(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    56.37              nan       41              nan              nan     47.32m\n",
      "   1    63.94              nan      185              nan              nan     45.86m\n",
      "   2    72.62              nan       25              nan              nan     46.33m\n",
      "   3    80.54              nan       18              nan              nan     43.88m\n",
      "   4    86.16              nan       63              nan              nan     43.39m\n",
      "   5    90.19              nan       10              nan              nan     48.65m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env\\lib\\site-packages\\gplearn\\functions.py:46: RuntimeWarning: overflow encountered in subtract\n",
      "  return self.function(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6    94.50              nan       80              nan              nan     42.28m\n",
      "   7    97.62              nan       41              nan              nan     39.85m\n",
      "   8   103.19              nan       22              nan              nan     43.79m\n",
      "   9   106.83              nan      213              nan              nan     53.54m\n",
      "  10   113.59              nan      180              nan              nan     35.03m\n",
      "  11   118.24              nan       47              nan              nan     31.27m\n",
      "  12   124.56              nan       22              nan              nan     31.13m\n",
      "  13   129.84              nan      161              nan              nan     22.44m\n",
      "  14   134.74              nan      165              nan              nan     23.84m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# entrenando modelo \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Modelo\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SymbolicRegressor(population_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m,\n\u001b[0;32m      5\u001b[0m                         generations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, \n\u001b[0;32m      6\u001b[0m                         stopping_criteria\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m                         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     16\u001b[0m                         function_set\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmul\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m,pot, pot2])\n\u001b[1;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Obtener la expresión simbólica\u001b[39;00m\n\u001b[0;32m     21\u001b[0m expression \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_program\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\gplearn\\genetic.py:476\u001b[0m, in \u001b[0;36mBaseSymbolic.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    472\u001b[0m n_jobs, n_programs, starts \u001b[38;5;241m=\u001b[39m _partition_estimators(\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    474\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation_size)\n\u001b[1;32m--> 476\u001b[0m population \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_evolve\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_programs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m                              \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m                              \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# Reduce, maintaining order across different n_jobs\u001b[39;00m\n\u001b[0;32m    488\u001b[0m population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(population))\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\gplearn\\genetic.py:147\u001b[0m, in \u001b[0;36m_parallel_evolve\u001b[1;34m(n_programs, parents, X, y, sample_weight, seeds, params)\u001b[0m\n\u001b[0;32m    144\u001b[0m curr_sample_weight[not_indices] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    145\u001b[0m oob_sample_weight[indices] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 147\u001b[0m program\u001b[38;5;241m.\u001b[39mraw_fitness_ \u001b[38;5;241m=\u001b[39m \u001b[43mprogram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_samples \u001b[38;5;241m<\u001b[39m n_samples:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# Calculate OOB fitness\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     program\u001b[38;5;241m.\u001b[39moob_fitness_ \u001b[38;5;241m=\u001b[39m program\u001b[38;5;241m.\u001b[39mraw_fitness(X, y, oob_sample_weight)\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\gplearn\\_program.py:462\u001b[0m, in \u001b[0;36m_Program.raw_fitness\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_fitness\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight):\n\u001b[0;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the raw fitness of the program according to X, y.\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    460\u001b[0m \n\u001b[0;32m    461\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer:\n\u001b[0;32m    464\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(y_pred)\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\gplearn\\_program.py:380\u001b[0m, in \u001b[0;36m_Program.execute\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    376\u001b[0m function \u001b[38;5;241m=\u001b[39m apply_stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    377\u001b[0m terminals \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrepeat(t, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, \u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m    378\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m X[:, t] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    379\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m apply_stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:]]\n\u001b[1;32m--> 380\u001b[0m intermediate_result \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mterminals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(apply_stack) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    382\u001b[0m     apply_stack\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\gplearn\\functions.py:46\u001b[0m, in \u001b[0;36m_Function.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\joblib\\externals\\loky\\cloudpickle_wrapper.py:32\u001b[0m, in \u001b[0;36mCallableObjectWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[19], line 16\u001b[0m, in \u001b[0;36mpot2\u001b[1;34m(x1, A, B)\u001b[0m\n\u001b[0;32m     14\u001b[0m con3 \u001b[38;5;241m=\u001b[39m (A \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m&\u001b[39m (A \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 16\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(con1  , A \u001b[38;5;241m*\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# entrenando modelo \n",
    "\n",
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 8.0),\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.01, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot, pot2])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste automatico de toda la funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1^A + B*x2^C\n",
    "\n",
    "def pot(x1, x2,A,B,C):\n",
    "    con1 = (x1 > 0)\n",
    "    con2 = (x2 > 0)\n",
    "    con3 = (A >= -1) & (A < 0)\n",
    "    con4 = (B > 1)\n",
    "    con5 = (A >= -1) & (A < 0)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(con1 & con2 & con3 & con4 & con5, np.power(x1,A) + B*np.power(x2,C), 0)\n",
    "    return result\n",
    "\n",
    "pot= make_function(function=pot, name='pot', arity=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_2232\\1665499163.py:10: RuntimeWarning: overflow encountered in power\n",
      "  result = np.where(con1 & con2 & con3 & con4 & con5, np.power(x1,A) + B*np.power(x2,C), 0)\n",
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_2232\\1665499163.py:10: RuntimeWarning: overflow encountered in multiply\n",
      "  result = np.where(con1 & con2 & con3 & con4 & con5, np.power(x1,A) + B*np.power(x2,C), 0)\n",
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_2232\\1665499163.py:10: RuntimeWarning: overflow encountered in add\n",
      "  result = np.where(con1 & con2 & con3 & con4 & con5, np.power(x1,A) + B*np.power(x2,C), 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  2815.54          2.57224      631         0.938607         0.969947   3720.94m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:573: RuntimeWarning: invalid value encountered in multiply\n",
      "  avg = avg_as_array = np.multiply(a, wgt,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1    21.82              nan        6              nan              nan     30.28m\n",
      "   2     5.46              nan        6              nan              nan      9.70m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env\\lib\\site-packages\\numpy\\_core\\_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3     2.44              nan        6              nan              nan      6.39m\n",
      "   4     6.24              nan        6              nan              nan      9.74m\n",
      "   5     7.67              nan       11              nan              nan     10.96m\n",
      "   6     8.45              nan       11              nan              nan     10.30m\n",
      "   7     9.97              nan       11              nan              nan     10.41m\n",
      "   8    10.77              nan       11              nan              nan     10.77m\n",
      "   9    11.86              nan       16              nan              nan     10.37m\n",
      "  10    12.90              nan        6              nan              nan      9.66m\n",
      "  11    14.39              nan       21              nan              nan      9.18m\n",
      "  12    15.51              nan       36              nan              nan     10.77m\n",
      "  13    16.83              nan       11              nan              nan     11.57m\n",
      "  14    18.13              nan       11              nan              nan      8.81m\n",
      "  15    20.36              nan       16              nan              nan      7.33m\n",
      "  16    22.18              nan        6              nan              nan      5.27m\n",
      "  17    24.17              nan       16              nan              nan      3.94m\n",
      "  18    26.53              nan       11              nan              nan      2.26m\n",
      "  19    28.81              nan       11              nan              nan      0.00s\n",
      "Expresión: pot(X0, pot(3.293, 1.290, -0.882, 2.797, 3.293), -0.056, X0, X1)\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.01, \n",
    "                        random_state=0,\n",
    "                        function_set=[pot])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdrag(S, Re):\n",
    "    return S**(-0.6) + 5*Re**(-0.23)\n",
    "\n",
    "def cdrag_gp(S, Re):\n",
    "    return S**(-0.056) + S*(6.450**Re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_2232\\2361799520.py:5: RuntimeWarning: overflow encountered in scalar power\n",
      "  return S**(-0.056) + S*(6.450**Re)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m mape_cdrag \u001b[38;5;241m=\u001b[39m mean_absolute_percentage_error(y_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdrag\u001b[39m\u001b[38;5;124m'\u001b[39m], cdrag_pred)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calcular R^2 y MSE para cdrag_gp\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m r2_cdrag_gp \u001b[38;5;241m=\u001b[39m \u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcdrag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcdrag_gp_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m mse_cdrag_gp \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdrag\u001b[39m\u001b[38;5;124m'\u001b[39m], cdrag_gp_pred)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Calcular MAE y MAPE para cdrag_gp\u001b[39;00m\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:1204\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m   1198\u001b[0m xp, _, device_ \u001b[38;5;241m=\u001b[39m get_namespace_and_device(\n\u001b[0;32m   1199\u001b[0m     y_true, y_pred, sample_weight, multioutput\n\u001b[0;32m   1200\u001b[0m )\n\u001b[0;32m   1202\u001b[0m dtype \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1204\u001b[0m _, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    116\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Calcular cdrag_pred y cdrag_gp_pred en vectores separados\n",
    "cdrag_pred = X_test.apply(lambda row: cdrag(row['K'], row['Rem']), axis=1).values\n",
    "cdrag_gp_pred = X_test.apply(lambda row: cdrag_gp(row['K'], row['Rem']), axis=1).values\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag\n",
    "r2_cdrag = r2_score(y_test['cdrag'], cdrag_pred)\n",
    "mse_cdrag = mean_squared_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag\n",
    "mae_cdrag = mean_absolute_error(y_test['cdrag'], cdrag_pred)\n",
    "mape_cdrag = mean_absolute_percentage_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag_gp\n",
    "r2_cdrag_gp = r2_score(y_test['cdrag'], cdrag_gp_pred)\n",
    "mse_cdrag_gp = mean_squared_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag_gp\n",
    "mae_cdrag_gp = mean_absolute_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "mape_cdrag_gp = mean_absolute_percentage_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "#  Mostrar Metricas \n",
    "\n",
    "print(f\"R^2 cdrag original: {r2_cdrag}, R^2 cdrag GPLearn: {r2_cdrag_gp} \")\n",
    "print(f\"MSE cdrag original: {mse_cdrag}, MSE cdrag GPLearn: {mse_cdrag_gp} \")\n",
    "print(f\"MAE cdrag original: {mae_cdrag}, MAE cdrag GPLearn: {mae_cdrag_gp} \")\n",
    "print(f\"MAPE cdrag original: {mape_cdrag*100}*100, MAPE cdrag GPLearn: {mape_cdrag_gp*100}*100 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste automatico de constante V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A* x ^ B\n",
    "\n",
    "def pot(x1, A, B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B >= -1) & (B < 0)\n",
    "    con3 = (A>=1) & (A<10)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = np.where(con1 & con2 & con3, A*np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot_fn= make_function(function=pot, name='pot', arity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_3488\\2416824652.py:8: RuntimeWarning: overflow encountered in power\n",
      "  result = np.where(con1 & con2 & con3, A*np.power(x1,B), 0)\n",
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_3488\\2416824652.py:8: RuntimeWarning: overflow encountered in multiply\n",
      "  result = np.where(con1 & con2 & con3, A*np.power(x1,B), 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    60.02      4.93357e+19        8         0.192673          0.20065     38.60m\n",
      "   1    43.77        8.862e+11        3         0.147749         0.152491     32.36m\n",
      "   2    66.25      1.06883e+08        3         0.147998         0.150302     34.63m\n",
      "   3    99.30      4.06181e+08        3         0.147223         0.157007     50.21m\n",
      "   4    35.14      1.60696e+08        3         0.147126         0.157825     17.27m\n",
      "   5    18.18       3.4603e+08       11          0.14405         0.144626      9.76m\n",
      "   6     3.59      5.27281e+07       11         0.143378         0.150512      3.42m\n",
      "   7     3.63      2.64035e+07       11          0.14344          0.14998      2.44m\n",
      "   8     4.48           109347       11         0.142535         0.157556      2.22m\n",
      "   9     8.12      3.24308e+07       11         0.142752         0.155775      2.41m\n",
      "  10    10.97      5.36069e+07       11         0.142955         0.154093      2.68m\n",
      "  11    11.20      1.01141e+12       11         0.142791         0.155455      2.38m\n",
      "  12    11.14       2.7049e+07       11         0.142738         0.155891      2.18m\n",
      "  13    10.99      5.82522e+07       13         0.141827         0.143138      1.87m\n",
      "  14    11.21          68621.2       13         0.141421         0.144019      1.30m\n",
      "  15    11.31      2.68085e+07       13         0.140685         0.150369      1.07m\n",
      "  16    11.25      1.78702e+08       13         0.140701         0.152815     48.35s\n",
      "  17    11.68      2.65523e+07       13         0.140609         0.151012     38.48s\n",
      "  18    12.55      3.52867e+07       13         0.140533         0.151642     17.93s\n",
      "  19    13.03      2.09238e+11       15         0.139877         0.150587      0.00s\n",
      "Expresión: sub(mul(-0.586, div(sub(2.863, mul(S, mul(S, S))), 8.637)), sub(S, 2.998))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-4, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn],\n",
    "                        metric = 'rmse', \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.021153612653894996\n",
      "R^2: 0.800101026692717\n"
     ]
    }
   ],
   "source": [
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento: probando RMSLE para calcular el fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A* x ^ B\n",
    "\n",
    "def pot(x1, A, B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    con3 = (A>=1) & (A<10)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2 & con3, A*np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot_fn= make_function(function=pot, name='pot', arity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiendo \n",
    "\n",
    "def _rmsle(y, y_pred, w):\n",
    "    \"\"\"Calculate the rmsle.\"\"\"\n",
    "    log_true = np.log((np.maximum(0.001, y) + 1))\n",
    "    log_pred = np.log((np.maximum(0.001, y_pred) + 1))\n",
    "    \n",
    "    # Calcular el error cuadrático medio logarítmico\n",
    "    rmsle_value = (log_pred - log_true) ** 2\n",
    "    \n",
    "    return np.sqrt(np.average(rmsle_value, weights=w))\n",
    "\n",
    "rmsle = make_fitness(function=_rmsle,\n",
    "                    greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   563.72          2.36735      110         0.100407        0.0977346    285.57m\n",
      "   1   140.85         0.739198      104        0.0870931        0.0874299     70.84m\n",
      "   2    77.52          0.70002       32        0.0646664        0.0660774     42.79m\n",
      "   3    61.79          0.79886       99        0.0602612        0.0615921     31.66m\n",
      "   4    20.49         0.990882       37        0.0480875          0.04882     12.88m\n",
      "   5     6.99         0.829384       37        0.0478952        0.0504926      7.55m\n",
      "   6     8.06         0.709249       24        0.0469346        0.0476777      6.75m\n",
      "   7    17.53         0.745621       35        0.0465678           0.0457      9.87m\n",
      "   8    20.97         0.678015       30        0.0465288        0.0471719     10.88m\n",
      "   9    12.98         0.706076       21        0.0458087        0.0472735      6.67m\n",
      "  10     6.26         0.604852        7        0.0467214        0.0492329      4.22m\n",
      "  11     6.16         0.584405        7        0.0466983        0.0494297      3.30m\n",
      "  12     6.52         0.653428        7         0.046652        0.0498212      2.82m\n",
      "  13     6.91          0.54657        9         0.046012        0.0473151      2.36m\n",
      "  14     5.07         0.499271        7        0.0466415        0.0499096      1.97m\n",
      "  15     3.92           0.4131        3        0.0496526        0.0536549      1.45m\n",
      "  16     4.19         0.444539        3        0.0496527         0.053654      1.08m\n",
      "  17     4.31         0.412039        3        0.0494469        0.0518682     48.68s\n",
      "  18     4.06         0.418806        3        0.0494107        0.0521784     24.18s\n",
      "  19     4.28         0.452406        3        0.0493385        0.0519272      0.00s\n",
      "Expresión: sub(2.884, S)\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-3, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento: probando RMSLE para calcular el fitness V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x ^ B\n",
    "\n",
    "def pot(x1, B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<10)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2 , np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot_fn= make_function(function=pot, name='pot', arity=2)\n",
    "\n",
    "def pot2(x1, A, B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    con3 = (A>=1) & (A<10)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2 & con3 , A*np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot2_fn= make_function(function=pot2, name='pot2', arity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiendo \n",
    "\n",
    "def _rmsle(y, y_pred, w):\n",
    "    \"\"\"Calculate the rmsle.\"\"\"\n",
    "    log_true = np.log((np.maximum(0.001, y) + 1))\n",
    "    log_pred = np.log((np.maximum(0.001, y_pred) + 1))\n",
    "    \n",
    "    # Calcular el error cuadrático medio logarítmico\n",
    "    rmsle_value = (log_pred - log_true) ** 2\n",
    "    \n",
    "    return np.sqrt(np.average(rmsle_value, weights=w))\n",
    "\n",
    "rmsle = make_fitness(function=_rmsle,\n",
    "                    greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   517.99          1.39167      119        0.0570374              N/A    201.88m\n",
      "   1   270.55         0.458137      123        0.0570374              N/A     93.21m\n",
      "   2   327.15         0.295014       94        0.0515898              N/A    112.78m\n",
      "   3   108.13         0.395088      113         0.045678              N/A     34.03m\n",
      "   4    97.62         0.369287      117         0.045678              N/A     31.41m\n",
      "   5    75.96         0.569397      143         0.045678              N/A     24.19m\n",
      "   6    95.41         0.509861      110        0.0444863              N/A     28.50m\n",
      "   7    73.24         0.581488      110        0.0444863              N/A     23.73m\n",
      "   8    52.62          0.52264       52          0.04387              N/A     20.95m\n",
      "   9    42.97         0.528195       62          0.04387              N/A     15.46m\n",
      "  10    36.08          0.53148       54        0.0400157              N/A     10.04m\n",
      "  11    31.21         0.556151       64        0.0400157              N/A      7.62m\n",
      "  12    27.05         0.565734       34        0.0391119              N/A      6.60m\n",
      "  13    31.18         0.606128       55        0.0372706              N/A     12.74m\n",
      "  14    45.99         0.588587       50        0.0369192              N/A      5.29m\n",
      "  15    40.07         0.648105       56        0.0359717              N/A      3.25m\n",
      "  16    39.44         0.681962       56        0.0359717              N/A      3.11m\n",
      "  17    39.04         0.682963       52        0.0358636              N/A      3.21m\n",
      "  18    32.61         0.728296       52        0.0358636              N/A      1.10m\n",
      "  19    28.23         0.820845       45        0.0359717              N/A      0.00s\n",
      "Expresión: add(div(sub(pot(div(1.424, div(4.619, Re)), S), add(div(div(div(S, S), div(add(div(S, S), 1.424), Re)), add(S, Re)), 4.237)), sub(div(0.143, 1.365), add(add(add(S, 1.424), div(0.143, 1.365)), pot(S, Re)))), pot(Re, S))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-4, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.012509492548400569\n",
      "R^2: 0.8817868721558565\n",
      "MAE: 0.08364321560876715\n",
      "MAPE: 0.042665244354956916\n"
     ]
    }
   ],
   "source": [
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   517.99          1.39167      119        0.0570374              N/A    204.00m\n",
      "   1   139.45          0.55073      123        0.0570374              N/A     50.53m\n",
      "   2    89.61         0.513123       96        0.0449948              N/A     31.56m\n",
      "   3    88.00         0.517237      106        0.0449184              N/A     27.99m\n",
      "   4    56.89         0.599344       60        0.0424703              N/A     18.43m\n",
      "   5    42.81          0.71871       59        0.0424703              N/A     14.29m\n",
      "   6    31.06         0.682983       45        0.0422749              N/A     10.62m\n",
      "   7    29.93         0.641195       45        0.0422552              N/A      8.75m\n",
      "   8    32.35         0.567554       43        0.0420723              N/A      8.78m\n",
      "   9    31.30         0.563516       37        0.0420162              N/A      7.76m\n",
      "  10    26.48         0.573383       26        0.0421558              N/A      5.80m\n",
      "  11    22.43         0.574025       26        0.0421558              N/A      4.33m\n",
      "  12    17.97           0.5775       11         0.041644              N/A      2.88m\n",
      "  13    14.87         0.622557       11         0.041644              N/A      2.09m\n",
      "  14    12.58         0.664534       11         0.041644              N/A      1.36m\n",
      "  15    11.15         0.643603       11         0.041644              N/A     52.38s\n",
      "  16    11.04         0.655854       11         0.041644              N/A     39.25s\n",
      "  17    11.17         0.645997       11         0.041644              N/A     29.06s\n",
      "  18    11.08         0.626292       11         0.041644              N/A     15.10s\n",
      "  19    11.17          0.57806       11         0.041644              N/A      0.00s\n",
      "Expresión: add(div(add(S, 1.061), add(S, 0.202)), pot(Re, -0.273))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-3, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.018624350728263878\n",
      "R^2: 0.8240022330933063\n",
      "MAE: 0.10298233864038064\n",
      "MAPE: 0.053830547896066866\n"
     ]
    }
   ],
   "source": [
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdrag(S, Re):\n",
    "    return S**(-0.6) + 5*Re**(-0.23)\n",
    "\n",
    "def cdrag_gp(S, Re):\n",
    "    return (S+1.061)/(S+0.202) + Re**(-0.273)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 cdrag original: 0.8904926780136748, R^2 cdrag GPLearn: 0.8240567720947451 \n",
      "MSE cdrag original: 0.011588230963563853, MSE cdrag GPLearn: 0.018618579328381825 \n",
      "MAE cdrag original: 0.07580331737181549, MAE cdrag GPLearn: 0.10297576458038689 \n",
      "MAPE cdrag original: 3.7448292462961463*100, MAPE cdrag GPLearn: 5.383526642536919*100 \n"
     ]
    }
   ],
   "source": [
    "# Calcular cdrag_pred y cdrag_gp_pred en vectores separados\n",
    "cdrag_pred = X_test.apply(lambda row: cdrag(row['K'], row['Rem']), axis=1).values\n",
    "cdrag_gp_pred = X_test.apply(lambda row: cdrag_gp(row['K'], row['Rem']), axis=1).values\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag\n",
    "r2_cdrag = r2_score(y_test['cdrag'], cdrag_pred)\n",
    "mse_cdrag = mean_squared_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag\n",
    "mae_cdrag = mean_absolute_error(y_test['cdrag'], cdrag_pred)\n",
    "mape_cdrag = mean_absolute_percentage_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag_gp\n",
    "r2_cdrag_gp = r2_score(y_test['cdrag'], cdrag_gp_pred)\n",
    "mse_cdrag_gp = mean_squared_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag_gp\n",
    "mae_cdrag_gp = mean_absolute_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "mape_cdrag_gp = mean_absolute_percentage_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "#  Mostrar Metricas \n",
    "\n",
    "print(f\"R^2 cdrag original: {r2_cdrag}, R^2 cdrag GPLearn: {r2_cdrag_gp} \")\n",
    "print(f\"MSE cdrag original: {mse_cdrag}, MSE cdrag GPLearn: {mse_cdrag_gp} \")\n",
    "print(f\"MAE cdrag original: {mae_cdrag}, MAE cdrag GPLearn: {mae_cdrag_gp} \")\n",
    "print(f\"MAPE cdrag original: {mape_cdrag*100}*100, MAPE cdrag GPLearn: {mape_cdrag_gp*100}*100 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   517.99          1.39167      119        0.0570374              N/A    186.70m\n",
      "   1    56.90         0.945585      119        0.0570374              N/A     21.03m\n",
      "   2    20.89         0.882782       38        0.0636891              N/A      9.26m\n",
      "   3     5.63         0.715348        9        0.0464463              N/A      3.68m\n",
      "   4     2.42         0.335649        9        0.0464463              N/A      2.74m\n",
      "   5     1.52          0.14475        5        0.0468234              N/A      2.28m\n",
      "   6     3.19          0.19225        5        0.0468234              N/A      2.46m\n",
      "   7     3.07         0.202594        3        0.0540941              N/A      2.13m\n",
      "   8     3.10          0.19561        3        0.0540941              N/A      1.81m\n",
      "   9     3.07         0.180835        3        0.0540941              N/A      1.65m\n",
      "  10     3.05         0.192319        3        0.0540941              N/A      1.52m\n",
      "  11     3.16         0.191197        3        0.0540941              N/A      1.38m\n",
      "  12     3.05         0.194586        3        0.0540941              N/A      1.34m\n",
      "  13     3.08           0.1877        3        0.0540941              N/A      1.05m\n",
      "  14     3.06         0.192643        3        0.0540941              N/A     51.26s\n",
      "  15     3.04         0.187278        3        0.0540941              N/A     41.19s\n",
      "  16     3.07          0.19855        3        0.0540941              N/A     36.04s\n",
      "  17     3.18         0.204466        3        0.0540941              N/A     21.03s\n",
      "  18     3.20         0.189121        3        0.0540941              N/A     10.47s\n",
      "  19     3.17         0.192947        3        0.0540941              N/A      0.00s\n",
      "Expresión: sub(2.941, S)\n"
     ]
    }
   ],
   "source": [
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-2, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento: probando MALE para calcular el fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiendo \n",
    "\n",
    "def _male(y, y_pred, w):\n",
    "    \"\"\"Calculate the male.\"\"\"\n",
    "    log_true = np.log((np.maximum(0.001, y) + 1))\n",
    "    log_pred = np.log((np.maximum(0.001, y_pred) + 1))\n",
    "    \n",
    "    # Calcular el error cuadrático medio logarítmico\n",
    "    male_value = np.abs((log_pred - log_true))\n",
    "    \n",
    "    return np.sqrt(np.average(male_value, weights=w))\n",
    "\n",
    "male = make_fitness(function=_male,\n",
    "                    greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   517.99          1.05587      119         0.215437              N/A    192.56m\n",
      "   1   259.58         0.613986      123         0.215437              N/A    108.91m\n",
      "   2   346.57         0.405068      123         0.214324              N/A    146.62m\n",
      "   3   115.96         0.417321       84         0.190398              N/A     78.43m\n",
      "   4    90.38         0.439365       94         0.175326              N/A     73.69m\n",
      "   5    64.18         0.528701       97         0.175326              N/A     49.56m\n",
      "   6    73.09          0.51716       98         0.173164              N/A     37.03m\n",
      "   7    89.80         0.472591       99         0.166231              N/A     22.36m\n",
      "   8    85.97         0.445841       95         0.166231              N/A     18.21m\n",
      "   9    69.90         0.503814       93          0.16623              N/A     14.61m\n",
      "  10    76.17         0.482119       94         0.164192              N/A     13.47m\n",
      "  11    86.42         0.442287      118         0.164192              N/A     12.34m\n",
      "  12    65.89         0.491896       93         0.164188              N/A      9.38m\n",
      "  13    55.22         0.520012       54         0.164192              N/A      6.94m\n",
      "  14    48.35         0.542401       71         0.164192              N/A      5.30m\n",
      "  15    42.45         0.556288       56         0.164178              N/A      3.44m\n",
      "  16    39.81         0.580583       34         0.164005              N/A      2.35m\n",
      "  17    39.25         0.577121       25         0.164005              N/A      1.57m\n",
      "  18    38.41         0.592445       47         0.163488              N/A     45.98s\n",
      "  19    34.68         0.602501       39          0.16353              N/A      0.00s\n",
      "Expresión: div(sub(pot(S, S), add(div(div(div(S, S), div(2.648, Re)), add(S, Re)), 4.237)), sub(mul(add(div(div(div(S, S), div(2.648, Re)), add(S, Re)), 4.237), div(4.619, Re)), add(S, 1.424)))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-4, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        metric = male, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento: escalar las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Conclusión: no funcionó. No se considera el Reynolds, o solía aproximar la función a una ecuación lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiendo conjunto de train\n",
    "df_cdrag_train = pd.concat([df_cdrag_25, df_cdrag_74], ignore_index=True)\n",
    "\n",
    "# separando entre x e y\n",
    "y_train = df_cdrag_train.drop(columns=['Current','K','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido','n_celda','Rem','colIndex'])\n",
    "X_train = df_cdrag_train.drop(columns=['Current','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido',\n",
    "                                    'n_celda','colIndex','cdrag'])\n",
    "\n",
    "\n",
    "# definiendo conjunto de test\n",
    "\n",
    "y_test = df_cdrag_53.drop(columns=['Current','K','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido','n_celda','Rem','colIndex'])\n",
    "X_test = df_cdrag_53.drop(columns=['Current','Flujo','t_viento','Diametro','col_fluido','col_celda','n_fluido',\n",
    "                                    'n_celda','colIndex','cdrag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "y_train_scaled = scaler.fit_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 ^ B\n",
    "\n",
    "def pot(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<10)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2 ,np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot_fn= make_function(function=pot, name='pot', arity=2)\n",
    "\n",
    "# A* X1 ^B\n",
    "def pot2(x1,A, B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    con3 = (A>=1) & (A<10)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2 & con3 ,A*np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot2_fn= make_function(function=pot2, name='pot2', arity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   517.99         0.400563     1691        0.0620841              N/A    189.10m\n",
      "   1    53.81         0.305262      213        0.0636314              N/A     17.21m\n",
      "   2    35.65         0.294892       31        0.0572523              N/A     12.14m\n",
      "   3    30.07         0.243388       31        0.0572523              N/A      8.82m\n",
      "   4    15.23         0.272991       34         0.052681              N/A      4.92m\n",
      "   5    14.56         0.257746       13        0.0395187              N/A      5.54m\n",
      "   6    22.65         0.197383       13        0.0395187              N/A      6.90m\n",
      "   7    17.39         0.211856       13        0.0393614              N/A      5.20m\n",
      "   8    12.46         0.214674       13        0.0393614              N/A      3.36m\n",
      "   9     9.04         0.215736       13        0.0393614              N/A      2.31m\n",
      "  10     6.90         0.199635       13        0.0393614              N/A      1.85m\n",
      "  11     6.33         0.177951       11        0.0371672              N/A      1.60m\n",
      "  12     7.67         0.186226       11        0.0371672              N/A      1.42m\n",
      "  13    10.07         0.197165       11        0.0371672              N/A      1.30m\n",
      "  14    12.27         0.183419       11        0.0371672              N/A      1.13m\n",
      "  15    12.88         0.180865       11        0.0371672              N/A     55.21s\n",
      "  16    12.89         0.181397       11        0.0371672              N/A     40.87s\n",
      "  17    12.71         0.182598       11        0.0371672              N/A     27.66s\n",
      "  18    12.34         0.181493       11        0.0371672              N/A     13.50s\n",
      "  19    11.76          0.17417       11        0.0371672              N/A      0.00s\n",
      "Expresión: sub(0.587, mul(div(1.011, 4.494), add(add(S, Re), S)))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-3, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train_scaled,y_train_scaled)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0035734637729696386\n",
      "R^2: 0.8677315986042082\n",
      "MAE: 0.044905556187363874\n",
      "MAPE: 24885354781.94131\n"
     ]
    }
   ],
   "source": [
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "y_test_scaled = scaler.fit_transform(y_test)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test_scaled, y_pred)\n",
    "r2 = r2_score(y_test_scaled, y_pred)\n",
    "mae = mean_absolute_error(y_test_scaled, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test_scaled, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste automatico de constante Vn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 ^ B\n",
    "\n",
    "def pot(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<10)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2 ,np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot_fn= make_function(function=pot, name='pot', arity=2)\n",
    "\n",
    "# 5* X1 ^B\n",
    "def pot2(x1, B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<10)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2 ,5*np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot2_fn= make_function(function=pot2, name='pot2', arity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    40.13          1.63734       63        0.0609554         0.060432     29.69m\n",
      "   1    27.90          0.88399        5        0.0597663        0.0592614     21.08m\n",
      "   2    35.11         0.825523      109        0.0576371        0.0569709     21.45m\n",
      "   3    33.09         0.723208        5        0.0455831        0.0473043     22.93m\n",
      "   4    25.66          0.70909        5        0.0457082        0.0462047     17.72m\n",
      "   5    12.40         0.608055        5        0.0455714        0.0474058      7.14m\n",
      "   6     6.06         0.471864        5        0.0454279        0.0486292      3.74m\n",
      "   7     5.49         0.409861        5        0.0453854        0.0489855      3.84m\n",
      "   8     5.26         0.427488        5        0.0453314        0.0494328      4.13m\n",
      "   9     5.40         0.401707        5        0.0453427        0.0493397      3.61m\n",
      "  10     5.22         0.382668        5        0.0452737        0.0499069      3.18m\n",
      "  11     5.32         0.384426        5        0.0453403        0.0493593      3.03m\n",
      "  12     5.24         0.383058        5        0.0453793        0.0490358      2.62m\n",
      "  13     5.30         0.386723        5        0.0452653        0.0499752      2.22m\n",
      "  14     5.21         0.402231        5        0.0453503        0.0492768      1.78m\n",
      "  15     5.26          0.38879        7        0.0437013        0.0415225      1.41m\n",
      "  16     5.32         0.394976        7        0.0435748        0.0427021      1.08m\n",
      "  17     5.35         0.368657        7        0.0433618         0.044611     47.03s\n",
      "  18     5.34         0.374476        7        0.0433582        0.0446426     21.59s\n",
      "  19     5.47         0.429798        7        0.0432202        0.0458315      0.00s\n",
      "Expresión: add(pot(Re, -0.031), pot(S, -0.656))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.001, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.018859381225995866\n",
      "R^2: 0.8217812245137683\n",
      "MAE: 0.10151616114359971\n",
      "MAPE: 0.051538457694427275\n"
     ]
    }
   ],
   "source": [
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdrag(S, Re):\n",
    "    return S**(-0.6) + 5*Re**(-0.23)\n",
    "\n",
    "def cdrag_gp(S, Re):\n",
    "    return S**(-0.656) + Re**(-0.031)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 cdrag original: 0.8904926780136748, R^2 cdrag GPLearn: 0.8231231569051083 \n",
      "MSE cdrag original: 0.011588230963563853, MSE cdrag GPLearn: 0.018717375904285256 \n",
      "MAE cdrag original: 0.07580331737181549, MAE cdrag GPLearn: 0.10101354711145066 \n",
      "MAPE cdrag original: 3.7448292462961463*100, MAPE cdrag GPLearn: 5.135779418892614*100 \n"
     ]
    }
   ],
   "source": [
    "# Calcular cdrag_pred y cdrag_gp_pred en vectores separados\n",
    "cdrag_pred = X_test.apply(lambda row: cdrag(row['K'], row['Rem']), axis=1).values\n",
    "cdrag_gp_pred = X_test.apply(lambda row: cdrag_gp(row['K'], row['Rem']), axis=1).values\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag\n",
    "r2_cdrag = r2_score(y_test['cdrag'], cdrag_pred)\n",
    "mse_cdrag = mean_squared_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag\n",
    "mae_cdrag = mean_absolute_error(y_test['cdrag'], cdrag_pred)\n",
    "mape_cdrag = mean_absolute_percentage_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag_gp\n",
    "r2_cdrag_gp = r2_score(y_test['cdrag'], cdrag_gp_pred)\n",
    "mse_cdrag_gp = mean_squared_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag_gp\n",
    "mae_cdrag_gp = mean_absolute_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "mape_cdrag_gp = mean_absolute_percentage_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "#  Mostrar Metricas \n",
    "\n",
    "print(f\"R^2 cdrag original: {r2_cdrag}, R^2 cdrag GPLearn: {r2_cdrag_gp} \")\n",
    "print(f\"MSE cdrag original: {mse_cdrag}, MSE cdrag GPLearn: {mse_cdrag_gp} \")\n",
    "print(f\"MAE cdrag original: {mae_cdrag}, MAE cdrag GPLearn: {mae_cdrag_gp} \")\n",
    "print(f\"MAPE cdrag original: {mape_cdrag*100}*100, MAPE cdrag GPLearn: {mape_cdrag_gp*100}*100 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    40.13      1.26092e+11        7          0.22805         0.225836     24.12m\n",
      "   1    25.30           124020        7         0.227215         0.233356     14.42m\n",
      "   2    32.01          52009.5        5         0.137923         0.139003     17.07m\n",
      "   3    13.79          45231.2        7         0.114091         0.113102      7.64m\n",
      "   4     6.84      1.99642e+07       13         0.106464         0.105984      4.10m\n",
      "   5     6.38          27784.4        9         0.103681         0.107175      3.16m\n",
      "   6     7.80      1.21515e+07        9         0.103775         0.106329      4.14m\n",
      "   7     4.47          31609.9        9         0.103531          0.10852      2.39m\n",
      "   8     4.11      6.78816e+07        9         0.103127         0.105615      1.89m\n",
      "   9     5.82          24328.3        9         0.103253          0.11102      2.14m\n",
      "  10     8.35          65022.7        9         0.103064         0.106189      2.91m\n",
      "  11     9.18      1.24156e+11        9         0.102808         0.108494      2.66m\n",
      "  12     9.24          36099.9        9          0.10248         0.111443      2.23m\n",
      "  13     9.25      3.66756e+07       11         0.101223         0.100386      1.95m\n",
      "  14     9.05          76796.1       11         0.101097         0.101515      1.60m\n",
      "  15     9.17          26527.1       11         0.100454         0.107304      1.28m\n",
      "  16     9.25            87273       11         0.100617          0.10584     57.79s\n",
      "  17     9.18          15562.6       11         0.100327         0.105883     39.59s\n",
      "  18     9.50      5.75543e+07       13        0.0990116        0.0991772     19.71s\n",
      "  19     9.63       1.8489e+07       13        0.0987329         0.101686      0.00s\n",
      "Expresión: add(pot(div(Re, S), -0.275), div(add(S, pot(2.553, -0.422)), S))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        const_range=(-1,8),\n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.001, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        #metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.020234249519583917\n",
      "R^2: 0.8087888924323552\n",
      "MAE: 0.09877020005507078\n",
      "MAPE: 0.05046559180367911\n"
     ]
    }
   ],
   "source": [
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdrag(S, Re):\n",
    "    return S**(-0.6) + 5*Re**(-0.23)\n",
    "\n",
    "def cdrag_gp(S, Re):\n",
    "    return (Re/S)**(-0.275) + ((S + 0.673324)/S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 cdrag original: 0.8904926780136748, R^2 cdrag GPLearn: 0.8087713914878053 \n",
      "MSE cdrag original: 0.011588230963563853, MSE cdrag GPLearn: 0.020236101496089648 \n",
      "MAE cdrag original: 0.07580331737181549, MAE cdrag GPLearn: 0.09876316341817992 \n",
      "MAPE cdrag original: 3.7448292462961463*100, MAPE cdrag GPLearn: 5.0466013800943825*100 \n"
     ]
    }
   ],
   "source": [
    "# Calcular cdrag_pred y cdrag_gp_pred en vectores separados\n",
    "cdrag_pred = X_test.apply(lambda row: cdrag(row['K'], row['Rem']), axis=1).values\n",
    "cdrag_gp_pred = X_test.apply(lambda row: cdrag_gp(row['K'], row['Rem']), axis=1).values\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag\n",
    "r2_cdrag = r2_score(y_test['cdrag'], cdrag_pred)\n",
    "mse_cdrag = mean_squared_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag\n",
    "mae_cdrag = mean_absolute_error(y_test['cdrag'], cdrag_pred)\n",
    "mape_cdrag = mean_absolute_percentage_error(y_test['cdrag'], cdrag_pred)\n",
    "\n",
    "# Calcular R^2 y MSE para cdrag_gp\n",
    "r2_cdrag_gp = r2_score(y_test['cdrag'], cdrag_gp_pred)\n",
    "mse_cdrag_gp = mean_squared_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "# Calcular MAE y MAPE para cdrag_gp\n",
    "mae_cdrag_gp = mean_absolute_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "mape_cdrag_gp = mean_absolute_percentage_error(y_test['cdrag'], cdrag_gp_pred)\n",
    "\n",
    "#  Mostrar Metricas \n",
    "\n",
    "print(f\"R^2 cdrag original: {r2_cdrag}, R^2 cdrag GPLearn: {r2_cdrag_gp} \")\n",
    "print(f\"MSE cdrag original: {mse_cdrag}, MSE cdrag GPLearn: {mse_cdrag_gp} \")\n",
    "print(f\"MAE cdrag original: {mae_cdrag}, MAE cdrag GPLearn: {mae_cdrag_gp} \")\n",
    "print(f\"MAPE cdrag original: {mape_cdrag*100} %, MAPE cdrag GPLearn: {mape_cdrag_gp*100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos: tomando como base el experimento  que resultó más parecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiendo \n",
    "\n",
    "def _rmsle(y, y_pred, w):\n",
    "    \"\"\"Calculate the rmsle.\"\"\"\n",
    "    log_true = np.log((np.maximum(0.001, y) + 1))\n",
    "    log_pred = np.log((np.maximum(0.001, y_pred) + 1))\n",
    "    \n",
    "    # Calcular el error cuadrático medio logarítmico\n",
    "    rmsle_value = (log_pred - log_true) ** 2\n",
    "    \n",
    "    return np.sqrt(np.average(rmsle_value, weights=w))\n",
    "\n",
    "rmsle = make_fitness(function=_rmsle,\n",
    "                    greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x ^ B\n",
    "\n",
    "def pot(x1, B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<10)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2 , np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot_fn= make_function(function=pot, name='pot', arity=2)\n",
    "\n",
    "def pot2(x1, A, B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    con3 = (A>1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2 & con3 , A*np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot2_fn= make_function(function=pot2, name='pot2', arity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    56.37          1.75501       50        0.0923517        0.0913985     34.16m\n",
      "   1    37.95         0.850732        9        0.0694237        0.0699577     18.85m\n",
      "   2    68.50         0.647001       22        0.0489846        0.0501482     28.26m\n",
      "   3    39.44          0.50415       22        0.0489074        0.0508216     24.08m\n",
      "   4    28.86         0.625064       19         0.048793        0.0565932     15.31m\n",
      "   5    30.13         0.508955       19        0.0473034        0.0456795     14.14m\n",
      "   6    11.52         0.651198       19         0.046933        0.0489973      4.85m\n",
      "   7     4.11         0.406052       19         0.046745         0.050589      2.96m\n",
      "   8     7.59         0.488108       17        0.0467047        0.0509229      2.96m\n",
      "   9    14.53         0.494768       16        0.0466583        0.0513042      3.39m\n",
      "  10    14.44         0.568774       21        0.0465957        0.0518143      2.69m\n",
      "  11    13.59          0.66015       13        0.0466368        0.0514803      2.23m\n",
      "  12    12.93         0.659421       15        0.0465618        0.0508644      1.96m\n",
      "  13    12.05         0.679304       15        0.0466159        0.0488729      1.62m\n",
      "  14    11.38         0.653196       13        0.0465683        0.0501476      1.56m\n",
      "  15    11.32         0.640889       11        0.0464821        0.0500068      1.32m\n",
      "  16    11.24         0.613913       20        0.0465824        0.0491599      1.19m\n",
      "  17    11.14         0.643163       11        0.0466138         0.051667     32.25s\n",
      "  18    11.25         0.609284       11        0.0464444        0.0503208     16.71s\n",
      "  19    11.27         0.636177       11        0.0463814        0.0508416      0.00s\n",
      "Expresión: add(div(add(S, 3.649), mul(5.979, S)), div(Re, Re))\n",
      "MSE: 0.022417091731561138\n",
      "R^2: 0.7881613086618968\n",
      "MAE: 0.10982783422877068\n",
      "MAPE: 0.05636356851673308\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.0001,\n",
    "                        const_range= (-1.0,8.0),\n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)\n",
    "\n",
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    56.37          1.75501       50        0.0923517        0.0913985     33.22m\n",
      "   1    36.54         0.860319        9        0.0694237        0.0699577     23.15m\n",
      "   2    56.43         0.698339       22        0.0489846        0.0501482     30.29m\n",
      "   3    23.44          0.85118       22        0.0489074        0.0508216     14.68m\n",
      "   4    16.20         0.983833       11        0.0478553         0.046934      9.60m\n",
      "   5    23.37          0.59883       19        0.0473034        0.0456795     10.50m\n",
      "   6     8.71         0.569801       19         0.046933        0.0489973      3.92m\n",
      "   7     3.40         0.375458        3        0.0491972        0.0529096      2.81m\n",
      "   8     3.47         0.397946        3        0.0491611        0.0532104      2.65m\n",
      "   9     3.41         0.391131        3        0.0491947        0.0529304      2.21m\n",
      "  10     3.43         0.382813        3        0.0491549        0.0532622      1.99m\n",
      "  11     3.44         0.382275        3        0.0490837        0.0538495      1.78m\n",
      "  12     3.41         0.375253        3        0.0491757         0.053089      1.77m\n",
      "  13     3.40         0.387442        3        0.0491759        0.0530873      1.38m\n",
      "  14     3.42         0.379955        3        0.0491572        0.0532429      1.11m\n",
      "  15     3.46         0.373572        3        0.0491624        0.0531997     53.39s\n",
      "  16     3.53         0.371806        3        0.0491116          0.05362     41.06s\n",
      "  17     3.48         0.378024        3        0.0491647        0.0531807     27.42s\n",
      "  18     3.41         0.380091        3        0.0491691        0.0531439     13.30s\n",
      "  19     3.43         0.381151        3        0.0491779        0.0530709      0.00s\n",
      "Expresión: sub(2.874, S)\n",
      "MSE: 0.02007506197563537\n",
      "R^2: 0.810293194658139\n",
      "MAE: 0.10944077968430656\n",
      "MAPE: 0.057662095057013744\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.0005,\n",
    "                        const_range= (-1.0,8.0),\n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)\n",
    "\n",
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    56.37       1.3351e+11       50         0.242531         0.239706     30.15m\n",
      "   1    37.97      2.60658e+08      178         0.143973         0.142393     19.77m\n",
      "   2    70.71           106356       19         0.109815         0.110065     31.71m\n",
      "   3    38.63      1.22593e+06       19         0.109389         0.113897     16.88m\n",
      "   4    97.01      4.15771e+07       19         0.108969         0.117671     32.36m\n",
      "   5    56.54       1.6338e+06       17         0.107266         0.114041     17.40m\n",
      "   6    18.33      3.07708e+07       11         0.108225         0.111264      5.74m\n",
      "   7    15.08          21738.1       17         0.107204           0.1146      3.55m\n",
      "   8    14.13          13224.5       17         0.107267         0.114033      2.85m\n",
      "   9    13.54          10656.1       33         0.106518         0.105166      2.67m\n",
      "  10    13.07          11972.1       43         0.105261          0.10671      2.36m\n",
      "  11    12.82          17604.2       39         0.105331         0.106079      2.13m\n",
      "  12    13.27          12200.2       43         0.104881         0.106433      1.95m\n",
      "  13    13.92          13782.5       41         0.105183         0.111931      1.88m\n",
      "  14    13.78          11888.9       15         0.105598         0.109761      1.27m\n",
      "  15    13.43      1.86244e+07       17         0.100696         0.102071     54.13s\n",
      "  16    13.09          36990.9       17         0.100404         0.104701     38.49s\n",
      "  17    13.34          29826.1       17         0.100273         0.105879     28.53s\n",
      "  18    14.86      2.67582e+07       17        0.0990056         0.102779     12.99s\n",
      "  19    16.33      1.85267e+07       17        0.0987502         0.105077      0.00s\n",
      "Expresión: add(div(add(S, 3.787), mul(S, 6.015)), div(Re, sub(Re, mul(add(6.015, 3.787), 7.857))))\n",
      "MSE: 0.020948231167482883\n",
      "R^2: 0.8020418558523426\n",
      "MAE: 0.1031619090205427\n",
      "MAPE: 0.05433573778265883\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.0001,\n",
    "                        const_range= (-1.0,8.0),\n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        #metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)\n",
    "\n",
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    56.37       1.3351e+11       50         0.242531         0.239706     32.28m\n",
      "   1    34.83      2.60649e+08      178         0.143973         0.142393     26.39m\n",
      "   2    58.97           103284       19         0.109815         0.110065     29.66m\n",
      "   3    24.40      5.99191e+07       19         0.109389         0.113897     12.38m\n",
      "   4    10.31      9.35729e+07       11          0.10883         0.105817      5.93m\n",
      "   5    17.86      1.85614e+07       17         0.107483         0.112088      8.62m\n",
      "   6     5.20      3.06696e+07       17         0.107869         0.108614      2.64m\n",
      "   7     3.39            40179        3         0.113536         0.121925      1.95m\n",
      "   8     3.47           140653        3         0.113514         0.122122      1.79m\n",
      "   9     3.41            15662        3         0.113536         0.121926      1.91m\n",
      "  10     3.43          23013.6        3         0.113405         0.123098      1.48m\n",
      "  11     3.44          20778.2        3         0.113338         0.123706      1.26m\n",
      "  12     3.41          24236.6        3         0.113567         0.121644      1.08m\n",
      "  13     3.40          34504.5        3         0.113516         0.122106     56.89s\n",
      "  14     3.42          39177.8        3         0.113453         0.122669     45.69s\n",
      "  15     3.46      1.86358e+07        3         0.113397         0.123173     36.72s\n",
      "  16     3.53          41436.4        3         0.113472         0.122495     28.93s\n",
      "  17     3.48      2.89851e+06        3         0.113271          0.12431     21.50s\n",
      "  18     3.41      4.52386e+07        3         0.113467          0.12254      9.21s\n",
      "  19     3.43      1.85126e+07        9         0.113422         0.119798      0.00s\n",
      "Expresión: sub(2.874, mul(div(S, Re), sub(Re, 2.076)))\n",
      "MSE: 0.020011287321498365\n",
      "R^2: 0.8108958571013631\n",
      "MAE: 0.10916816418199696\n",
      "MAPE: 0.057520437142674616\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.001,\n",
    "                        const_range= (-1.0,8.0),\n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        #metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)\n",
    "\n",
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    56.37          1.75503       50        0.0922568              N/A     16.73m\n",
      "   1    33.74         0.828189       32         0.076318              N/A     10.24m\n",
      "   2    44.46         0.688555       48        0.0495809              N/A     10.85m\n",
      "   3    18.03         0.792213       48        0.0495809              N/A      6.00m\n",
      "   4    14.07         0.861008       53        0.0495809              N/A      4.27m\n",
      "   5    17.44         0.595667        3        0.0495809              N/A      5.39m\n",
      "   6     8.14         0.556969        7        0.0495761              N/A      2.56m\n",
      "   7     3.52         0.331636        3        0.0495809              N/A      1.50m\n",
      "   8     3.47         0.381763        3        0.0495809              N/A      1.32m\n",
      "   9     3.39         0.384355        3        0.0495809              N/A      1.21m\n",
      "  10     3.48         0.396799        3        0.0495809              N/A      1.11m\n",
      "  11     3.42         0.386234        3        0.0495809              N/A     58.66s\n",
      "  12     3.52         0.389149        3        0.0495809              N/A      1.05m\n",
      "  13     3.41         0.397417        3        0.0495649              N/A     46.89s\n",
      "  14     3.58         0.379732        3        0.0495649              N/A     36.99s\n",
      "  15     3.45         0.378722        3        0.0495649              N/A     29.67s\n",
      "  16     3.53         0.378981        3        0.0495649              N/A     22.55s\n",
      "  17     3.35         0.376945        3        0.0495602              N/A     14.45s\n",
      "  18     3.48         0.362647        3        0.0495602              N/A      7.19s\n",
      "  19     3.41           0.3575        3        0.0495602              N/A      0.00s\n",
      "Expresión: sub(2.878, S)\n",
      "MSE: 0.020105480600028522\n",
      "R^2: 0.8100057424916887\n",
      "MAE: 0.10935509642881851\n",
      "MAPE: 0.057701312540061694\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.6, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=1.0, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.001,\n",
    "                        const_range= (-1.0,8.0),\n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)\n",
    "\n",
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    56.37          1.75503       50        0.0922568              N/A     25.85m\n",
      "   1    33.73         0.784317       32         0.076318              N/A     18.51m\n",
      "   2    44.45         0.646463       48        0.0495809              N/A     20.51m\n",
      "   3    17.16         0.720742       48        0.0495809              N/A      5.49m\n",
      "   4    14.29         0.658432       53        0.0495809              N/A      8.62m\n",
      "   5    12.40         0.531294       40        0.0495809              N/A      5.73m\n",
      "   6     4.01         0.332885        3        0.0495809              N/A      1.70m\n",
      "   7     3.20         0.226432        3        0.0495809              N/A      1.29m\n",
      "   8     3.25         0.251667        3        0.0495809              N/A      1.84m\n",
      "   9     3.15         0.255123        3        0.0495809              N/A      1.43m\n",
      "  10     3.25         0.266552        3        0.0495809              N/A      1.80m\n",
      "  11     3.25         0.262547        3        0.0495809              N/A      2.46m\n",
      "  12     3.18         0.267913        3        0.0495809              N/A      1.34m\n",
      "  13     3.21          0.27675        3        0.0495809              N/A     52.70s\n",
      "  14     3.25         0.268478        3        0.0495809              N/A      1.33m\n",
      "  15     3.18         0.236156        3        0.0495809              N/A      1.35m\n",
      "  16     3.30         0.242453        3        0.0495809              N/A     38.23s\n",
      "  17     3.18         0.257894        3        0.0495809              N/A     23.15s\n",
      "  18     3.19         0.252718        3        0.0495809              N/A     10.24s\n",
      "  19     3.18          0.24118        3        0.0495809              N/A      0.00s\n",
      "Expresión: sub(2.874, S)\n",
      "MSE: 0.02007506197563537\n",
      "R^2: 0.810293194658139\n",
      "MAE: 0.10944077968430656\n",
      "MAPE: 0.057662095057013744\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.6, \n",
    "                        p_subtree_mutation=0.05,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.05,\n",
    "                        max_samples=1.0, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.001,\n",
    "                        const_range= (-1.0,8.0),\n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)\n",
    "\n",
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    56.37      1.33638e+11       37         0.242223              N/A     16.71m\n",
      "   1    34.73      1.20269e+08       32         0.181036              N/A      9.73m\n",
      "   2    59.11           103177       48         0.114375              N/A     14.06m\n",
      "   3    23.13          79591.4       47         0.114019              N/A      6.48m\n",
      "   4    23.41           391714       55         0.114019              N/A      6.11m\n",
      "   5    30.24          56241.9       49         0.114019              N/A      8.06m\n",
      "   6     5.90          50147.4       24         0.114019              N/A      1.93m\n",
      "   7     3.23      1.83907e+07        3         0.114375              N/A      1.12m\n",
      "   8     3.25          67917.4        3         0.114375              N/A      1.01m\n",
      "   9     3.15            45197        3         0.114375              N/A      1.05m\n",
      "  10     3.25           236381        3         0.114375              N/A     51.44s\n",
      "  11     3.25      3.74561e+07        3         0.114375              N/A     43.55s\n",
      "  12     3.18      1.90422e+07        3         0.114375              N/A     38.79s\n",
      "  13     3.21          13455.2        3         0.114375              N/A     42.76s\n",
      "  14     3.25          15992.5        3         0.114375              N/A     28.66s\n",
      "  15     3.18          12548.1        3         0.114375              N/A     22.26s\n",
      "  16     3.30          23030.5        3         0.114375              N/A     17.10s\n",
      "  17     3.18      1.84046e+07        3         0.114375              N/A     10.94s\n",
      "  18     3.19      3.67627e+07        3         0.114375              N/A      5.55s\n",
      "  19     3.18      1.90438e+07        3         0.114375              N/A      0.00s\n",
      "Expresión: sub(2.874, S)\n",
      "MSE: 0.02007506197563537\n",
      "R^2: 0.810293194658139\n",
      "MAE: 0.10944077968430656\n",
      "MAPE: 0.057662095057013744\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.6, \n",
    "                        p_subtree_mutation=0.05,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.05,\n",
    "                        max_samples=1.0, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.001,\n",
    "                        const_range= (-1.0,8.0),\n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        #metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)\n",
    "\n",
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento: con solo una funcion potencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se demora demasiado en converger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _rmsle(y, y_pred, w):\n",
    "    \"\"\"Calculate the rmsle.\"\"\"\n",
    "    log_true = np.log((np.maximum(0.001, y) + 1))\n",
    "    log_pred = np.log((np.maximum(0.001, y_pred) + 1))\n",
    "    \n",
    "    # Calcular el error cuadrático medio logarítmico\n",
    "    rmsle_value = (log_pred - log_true) ** 2\n",
    "    \n",
    "    return np.sqrt(np.average(rmsle_value, weights=w))\n",
    "\n",
    "rmsle = make_fitness(function=_rmsle,\n",
    "                    greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevas combinaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pot(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2  ,np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot_fn= make_function(function=pot, name='pot', arity=2)\n",
    "\n",
    "def pot2(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2  ,np.dot(4,np.power(x1,B)), 0)\n",
    "    return result\n",
    "\n",
    "pot2_fn= make_function(function=pot2, name='pot2', arity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   291.55       1.7173e+21      111         0.190911              N/A    117.20m\n",
      "   1   137.68      2.62747e+07      111         0.190911              N/A     50.73m\n",
      "   2   133.02      8.74897e+10       89         0.190911              N/A     46.02m\n",
      "   3    69.74      6.47508e+11      115         0.150901              N/A     23.05m\n",
      "   4    59.87           116388       31         0.109058              N/A     19.23m\n",
      "   5    42.46      1.27483e+08       31         0.108969              N/A     13.00m\n",
      "   6    35.42      9.08531e+10       27         0.107343              N/A     11.08m\n",
      "   7    41.39      1.01484e+08       31         0.107343              N/A     11.11m\n",
      "   8    36.43           294194       33         0.107325              N/A      9.43m\n",
      "   9    27.54          1093.16       27         0.107343              N/A      5.71m\n",
      "  10    23.77          6218.71       23         0.107207              N/A      4.07m\n",
      "  11    21.26          12069.6       39         0.104604              N/A      3.14m\n",
      "  12    18.83          8439.91       23         0.107263              N/A      1.95m\n",
      "  13    17.49          21062.3       19         0.107263              N/A      1.34m\n",
      "  14    16.51           1959.2       19         0.107263              N/A     57.14s\n",
      "  15    15.43          10498.2       19         0.107263              N/A     51.13s\n",
      "  16    15.12            11894       15         0.107592              N/A     33.51s\n",
      "  17    14.99          3814.11       15         0.107539              N/A     23.35s\n",
      "  18    15.04          21978.7       15         0.107539              N/A     11.39s\n",
      "  19    15.08          22952.3       17         0.107375              N/A      0.00s\n",
      "Expresión: sub(div(5.622, 7.087), div(add(div(Re, S), Re), sub(8.905, add(Re, sub(Re, 9.300)))))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-3, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn,pot2_fn],\n",
    "                        #metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.02445910730007164\n",
      "R^2: 0.7688645189219384\n",
      "MAE: 0.11674923666488987\n",
      "MAPE: 0.05985176074507344\n"
     ]
    }
   ],
   "source": [
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   281.38      1.88996e+24       67         0.237109              N/A     78.93m\n",
      "   1   140.82      8.75988e+17        3         0.123755              N/A     36.92m\n",
      "   2   112.23           371630        3         0.123755              N/A     28.31m\n",
      "   3    44.25           153234        3         0.123755              N/A     13.73m\n",
      "   4    19.86          68494.6        3         0.123755              N/A      6.45m\n",
      "   5    37.69      1.41324e+07       63         0.108781              N/A      8.69m\n",
      "   6    22.71          76378.2       63         0.108781              N/A      5.49m\n",
      "   7     4.31          50198.3       37         0.112379              N/A      1.93m\n",
      "   8     3.15       1.0296e+08        3         0.123755              N/A      1.46m\n",
      "   9     3.04          2245.03        3         0.123755              N/A      1.23m\n",
      "  10     3.04            15490        3         0.123755              N/A      1.16m\n",
      "  11     3.06          4491.03        3         0.123755              N/A      1.04m\n",
      "  12     3.24           152231        3         0.123755              N/A     53.58s\n",
      "  13     3.11          9125.64        3         0.123755              N/A     45.27s\n",
      "  14     3.06          2302.23        3         0.123755              N/A     38.58s\n",
      "  15     3.06          26.4808        3         0.123755              N/A     31.31s\n",
      "  16     3.10          6957.57        3         0.123755              N/A     24.84s\n",
      "  17     3.07      1.32434e+07        3         0.123755              N/A     16.21s\n",
      "  18     3.02          2432.65        3         0.123755              N/A     11.08s\n",
      "  19     3.07            21586        3         0.123755              N/A      0.00s\n",
      "Expresión: sub(2.824, S)\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-3, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn],\n",
    "                        #metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   281.38          2.43121     1023         0.100842              N/A     88.27m\n",
      "   1   113.95         0.670959        3        0.0530797              N/A     30.64m\n",
      "   2    74.54         0.595175        3        0.0530797              N/A     20.35m\n",
      "   3    39.41         0.591902        3        0.0530797              N/A     13.06m\n",
      "   4    14.66         0.902904        3        0.0530797              N/A      5.62m\n",
      "   5    16.26          1.27397       37        0.0468881              N/A      6.06m\n",
      "   6     8.68         0.790204       37        0.0468881              N/A      3.33m\n",
      "   7     3.20         0.218879        7        0.0483221              N/A      2.08m\n",
      "   8     4.23         0.267706        9        0.0473653              N/A      1.95m\n",
      "   9     6.60         0.349922        9        0.0473653              N/A      1.82m\n",
      "  10     6.08         0.310333        9        0.0473653              N/A      1.83m\n",
      "  11     5.07         0.205446        7        0.0483221              N/A      1.53m\n",
      "  12     5.24         0.200006        5        0.0495838              N/A      1.29m\n",
      "  13     5.08         0.196064        5        0.0495838              N/A      1.09m\n",
      "  14     5.06         0.192285        5        0.0495838              N/A     53.46s\n",
      "  15     5.03         0.187931        5        0.0495838              N/A     44.33s\n",
      "  16     5.07         0.187369        5        0.0495838              N/A     33.04s\n",
      "  17     5.07         0.210429        5        0.0495838              N/A     22.46s\n",
      "  18     5.01         0.183814        5        0.0495838              N/A     10.75s\n",
      "  19     5.07          0.19625        5        0.0495838              N/A      0.00s\n",
      "Expresión: add(0.049, sub(2.824, S))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-3, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   291.55          1.35346      111        0.0859569              N/A    122.03m\n",
      "   1   111.87         0.531876       63        0.0787678              N/A     45.53m\n",
      "   2    85.69         0.498723       35        0.0497858              N/A     33.40m\n",
      "   3    52.60         0.728958       35        0.0497858              N/A     18.81m\n",
      "   4    32.38         0.941742       23        0.0497858              N/A     11.38m\n",
      "   5    19.08         0.909782        5        0.0463943              N/A      7.25m\n",
      "   6    23.00         0.475818        5        0.0463943              N/A      7.89m\n",
      "   7    10.12         0.693365        5        0.0463943              N/A      4.20m\n",
      "   8     6.53         0.586752        5        0.0463943              N/A      3.19m\n",
      "   9     4.04         0.344449        5        0.0463943              N/A      2.12m\n",
      "  10     3.92         0.394221        5        0.0463943              N/A      2.02m\n",
      "  11     5.00         0.462701        5        0.0463943              N/A      2.34m\n",
      "  12     5.06         0.473675        5        0.0463943              N/A      2.22m\n",
      "  13     5.08          0.47545        5        0.0463943              N/A      1.97m\n",
      "  14     5.07         0.464453        5        0.0463943              N/A      1.58m\n",
      "  15     5.04         0.472389        5        0.0463943              N/A      1.25m\n",
      "  16     5.05         0.469153        5        0.0463943              N/A      1.03m\n",
      "  17     5.06         0.485548        5        0.0463943              N/A     38.26s\n",
      "  18     5.07         0.479323        5        0.0450767              N/A     19.43s\n",
      "  19     5.12          0.46922        5        0.0450767              N/A      0.00s\n",
      "Expresión: pot2(mul(9.097, S), -0.358)\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-3, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn,pot2_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   291.55       1.7173e+21      111         0.190911              N/A    134.68m\n",
      "   1   137.68      2.62747e+07      111         0.190911              N/A     57.08m\n",
      "   2   133.02      8.74897e+10       89         0.190911              N/A     54.67m\n",
      "   3    69.74      6.47508e+11      115         0.150901              N/A     25.54m\n",
      "   4    59.87           116388       31         0.109058              N/A     22.06m\n",
      "   5    42.46      1.27483e+08       31         0.108969              N/A     13.64m\n",
      "   6    35.42      9.08531e+10       27         0.107343              N/A     10.25m\n",
      "   7    41.39      1.01484e+08       31         0.107343              N/A     11.97m\n",
      "   8    36.43           294194       33         0.107325              N/A     10.32m\n",
      "   9    27.54          1093.16       27         0.107343              N/A      6.19m\n",
      "  10    23.77          6218.71       23         0.107207              N/A      4.57m\n",
      "  11    21.26          12069.6       39         0.104604              N/A      3.08m\n",
      "  12    18.83          8439.91       23         0.107263              N/A      2.02m\n",
      "  13    17.49          21062.3       19         0.107263              N/A      1.53m\n",
      "  14    16.51           1959.2       19         0.107263              N/A     59.91s\n",
      "  15    15.43          10498.2       19         0.107263              N/A     46.39s\n",
      "  16    15.12            11894       15         0.107592              N/A     34.61s\n",
      "  17    14.99          3814.11       15         0.107539              N/A     22.66s\n",
      "  18    15.04          21978.7       15         0.107539              N/A     11.32s\n",
      "  19    15.08          22952.3       17         0.107375              N/A      0.00s\n",
      "Expresión: sub(div(5.622, 7.087), div(add(div(Re, S), Re), sub(8.905, add(Re, sub(Re, 9.300)))))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-3, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn,pot2_fn],\n",
    "                        #metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento: incorporar constantes cada una por separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pot(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2  ,np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot_fn= make_function(function=pot, name='pot', arity=2)\n",
    "\n",
    "def pot2(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2  ,np.dot(2,np.power(x1,B)), 0)\n",
    "    return result\n",
    "\n",
    "pot2_fn= make_function(function=pot2, name='pot2', arity=2)\n",
    "\n",
    "def pot3(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2  ,np.dot(3,np.power(x1,B)), 0)\n",
    "    return result\n",
    "\n",
    "pot3_fn= make_function(function=pot3, name='pot3', arity=2)\n",
    "\n",
    "def pot4(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2  ,np.dot(4,np.power(x1,B)), 0)\n",
    "    return result\n",
    "\n",
    "pot4_fn= make_function(function=pot4, name='pot4', arity=2)\n",
    "\n",
    "def pot5(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2  ,np.dot(5,np.power(x1,B)), 0)\n",
    "    return result\n",
    "\n",
    "pot5_fn= make_function(function=pot5, name='pot5', arity=2)\n",
    "\n",
    "def pot6(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2  ,np.dot(6,np.power(x1,B)), 0)\n",
    "    return result\n",
    "\n",
    "pot6_fn= make_function(function=pot6, name='pot6', arity=2)\n",
    "\n",
    "def pot7(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2  ,np.dot(7,np.power(x1,B)), 0)\n",
    "    return result\n",
    "\n",
    "pot7_fn= make_function(function=pot7, name='pot7', arity=2)\n",
    "\n",
    "def pot8(x1,B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2  ,np.dot(8,np.power(x1,B)), 0)\n",
    "    return result\n",
    "\n",
    "pot8_fn= make_function(function=pot8, name='pot8', arity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   328.86          1.03025      255         0.107091              N/A    235.77m\n",
      "   1   147.02         0.547944      133         0.107091              N/A     89.45m\n",
      "   2    63.82         0.442465       39         0.100068              N/A     36.92m\n",
      "   3    67.96         0.279877       45        0.0963336              N/A     36.87m\n",
      "   4    42.86         0.354817       37        0.0862953              N/A     23.74m\n",
      "   5    30.22         0.417715       15        0.0509017              N/A     16.00m\n",
      "   6    21.12         0.547346       15        0.0509017              N/A     10.79m\n",
      "   7    18.34         0.560621       17        0.0509017              N/A      8.69m\n",
      "   8    14.52          0.62582       45        0.0493318              N/A      6.78m\n",
      "   9    16.83         0.747499       57        0.0493318              N/A      6.53m\n",
      "  10    16.04         0.695039       27        0.0493662              N/A      5.98m\n",
      "  11    15.35         0.726399       15        0.0509017              N/A      5.23m\n",
      "  12    14.95         0.730282       15        0.0509017              N/A      4.50m\n",
      "  13    14.98         0.731294       15        0.0509017              N/A      3.84m\n",
      "  14    15.09         0.732865       15        0.0509017              N/A      3.20m\n",
      "  15    15.03         0.735881       15        0.0508803              N/A      2.58m\n",
      "  16    15.07         0.728832       15        0.0508803              N/A      1.91m\n",
      "  17    14.97         0.747429       25          0.05084              N/A      1.26m\n",
      "  18    14.97         0.715731       15        0.0508803              N/A     37.29s\n",
      "  19    15.06         0.721163       25          0.05084              N/A      0.00s\n",
      "Expresión: sub(div(div(add(pot4(Re, -0.206), S), sub(pot8(-0.511, Re), S)), Re), div(add(pot4(Re, -0.206), S), sub(pot8(-0.511, Re), S)))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-3, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn,pot2_fn,pot3_fn, pot4_fn, pot5_fn, pot6_fn, pot7_fn, pot8_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   328.86          1.03025      255         0.107091              N/A    210.09m\n",
      "   1    53.99         0.826497        3         0.102646              N/A     33.85m\n",
      "   2    31.63         0.611389        5        0.0911846              N/A     19.75m\n",
      "   3     7.74          0.80168        3        0.0537202              N/A      5.81m\n",
      "   4     4.03         0.499724        3        0.0537202              N/A      3.73m\n",
      "   5     2.81         0.237125        3        0.0537202              N/A      3.64m\n",
      "   6     2.57         0.205542        3        0.0537202              N/A      2.75m\n",
      "   7     3.09         0.193897        3        0.0537202              N/A      2.01m\n",
      "   8     3.07         0.190806        3        0.0537202              N/A      1.78m\n",
      "   9     3.05         0.185586        3        0.0537202              N/A      1.63m\n",
      "  10     3.04         0.188345        3        0.0537202              N/A      1.45m\n",
      "  11     3.16         0.191255        3        0.0537202              N/A      1.38m\n",
      "  12     3.08         0.188851        3        0.0537202              N/A      1.20m\n",
      "  13     3.06         0.187819        3        0.0537202              N/A     59.49s\n",
      "  14     3.04          0.18861        3        0.0537202              N/A     49.99s\n",
      "  15     3.06         0.185145        3        0.0537202              N/A     39.93s\n",
      "  16     3.09         0.191243        3        0.0537202              N/A     30.30s\n",
      "  17     3.10         0.201834        3        0.0537202              N/A     20.66s\n",
      "  18     3.07          0.18314        3        0.0537202              N/A      9.88s\n",
      "  19     3.10         0.190797        3        0.0537202              N/A      0.00s\n",
      "Expresión: sub(2.819, S)\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-2, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn,pot2_fn,pot3_fn, pot4_fn, pot5_fn, pot6_fn, pot7_fn, pot8_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0   319.27          1.04041        3        0.0746335              N/A    195.19m\n",
      "   1   141.13         0.513472        3        0.0746335              N/A     80.32m\n",
      "   2    68.45         0.418659        3        0.0628976              N/A     36.78m\n",
      "   3    63.36         0.309766        3        0.0628976              N/A     29.01m\n",
      "   4    31.14         0.574942        3        0.0628976              N/A     14.29m\n",
      "   5    13.79         0.697558        5        0.0578128              N/A      7.43m\n",
      "   6     5.74         0.424469        5        0.0578128              N/A      4.04m\n",
      "   7     3.26         0.202009        5        0.0578128              N/A      2.22m\n",
      "   8     3.50         0.204968        7        0.0468335              N/A      2.16m\n",
      "   9     4.96         0.220222        7        0.0468335              N/A      2.90m\n",
      "  10     6.99         0.227204        7        0.0468335              N/A      2.84m\n",
      "  11     7.03         0.214061        7        0.0468335              N/A      2.54m\n",
      "  12     7.04         0.223952        7        0.0468335              N/A      2.22m\n",
      "  13     7.07         0.224246        7        0.0468335              N/A      1.92m\n",
      "  14     7.09         0.226844        7        0.0468335              N/A      1.58m\n",
      "  15     7.03         0.223447        7        0.0468335              N/A      1.29m\n",
      "  16     7.07         0.216174        7        0.0468335              N/A     57.29s\n",
      "  17     7.02         0.230168        7        0.0468335              N/A     38.36s\n",
      "  18     7.02         0.223877        7        0.0468335              N/A     19.21s\n",
      "  19     7.09         0.218713        7        0.0468335              N/A      0.00s\n",
      "Expresión: add(-0.070, add(-0.070, pot2(S, -0.318)))\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=7000,\n",
    "                        init_depth=(5, 9),\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        const_range = (-1.0, 10.0),\n",
    "                        p_crossover=0.9,\n",
    "                        p_subtree_mutation=0.01, \n",
    "                        p_hoist_mutation=0.01, \n",
    "                        p_point_mutation=0.01, \n",
    "                        p_point_replace=0.05, \n",
    "                        max_samples=1.0,\n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=1e-3, \n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn,pot2_fn,pot3_fn, pot4_fn, pot5_fn, pot6_fn],\n",
    "                        metric = rmsle, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento: incorporar el logaritmo del coseno hiperbolico del error como fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x ^ B\n",
    "\n",
    "def pot(x1, B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1) & (B < 0)\n",
    "    #con3 = (A>=1) & (A<10)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2 , np.power(x1,B), 0)\n",
    "    return result\n",
    "\n",
    "pot_fn= make_function(function=pot, name='pot', arity=2)\n",
    "\n",
    "# A * x1 ^ B\n",
    "def pot2(x1, A, B):\n",
    "    con1 = x1 > 0\n",
    "    con2 = (B > -1.5) & (B < 0)\n",
    "    con3 = (A>1) & (A<8)\n",
    "    with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "        result = np.where(con1 & con2 & con3 , np.dot(A,np.power(x1,B)), 0)\n",
    "    return result\n",
    "\n",
    "pot2_fn= make_function(function=pot2, name='pot2', arity=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "L_{log-cosh} =  \\sum_{i} log(cosh((x_i - \\hat{x}_i)))\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logcosh(y, y_pred, w):\n",
    "    \"\"\"Calculate the log cos h.\"\"\"\n",
    "    #log_true = np.log((np.maximum(0.001, y) + 1))\n",
    "    #log_pred = np.log((np.maximum(0.001, y_pred) + 1))\n",
    "    loss = y_pred - y\n",
    "    \n",
    "    # Calcular el error cuadrático medio logarítmico\n",
    "    #log_value = np.log(np.cosh(loss))\n",
    "    \n",
    "    return np.mean(np.log(np.cosh(loss)))\n",
    "\n",
    "logcosh = make_fitness(function=_logcosh,\n",
    "                    greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_13408\\938827838.py:10: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(loss)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    56.37              inf       50         0.037821         0.037821     41.18m\n",
      "   1    34.48              inf      178        0.0169477        0.0169477     24.13m\n",
      "   2    47.59              nan       27              nan              nan     30.85m\n",
      "   3    17.49              nan       31              nan              nan     12.37m\n",
      "   4    10.82              nan       27              nan              nan     10.62m\n",
      "   5    16.90              nan       27              nan              nan     10.47m\n",
      "   6    32.30              nan       30              nan              nan     16.69m\n",
      "   7    36.93              nan       35              nan              nan     15.44m\n",
      "   8    42.05              nan       37              nan              nan     16.63m\n",
      "   9    47.56              nan       23              nan              nan     15.88m\n",
      "  10    53.33              nan       71              nan              nan     18.36m\n",
      "  11    59.69              nan       48              nan              nan     23.38m\n",
      "  12    65.51              nan       35              nan              nan     17.05m\n",
      "  13    72.04              nan       49              nan              nan     13.38m\n",
      "  14    77.61              nan       48              nan              nan     12.56m\n",
      "  15    84.91              nan       87              nan              nan     11.14m\n",
      "  16    90.87              nan       96              nan              nan     10.13m\n",
      "  17    98.32              nan      107              nan              nan      5.62m\n",
      "  18   105.25              nan      220              nan              nan      3.45m\n",
      "  19   113.01              nan      100              nan              nan      0.00s\n",
      "Expresión: sub(sub(sub(sub(S, 0.105), pot2(div(6.500, 1.363), div(6.500, 1.363), sub(sub(add(pot(pot2(S, 2.099, 6.118), 0.733), sub(4.777, S)), pot(pot2(S, S, S), sub(pot(7.915, 1.863), mul(Re, Re)))), sub(pot(Re, pot(pot2(5.959, 2.099, 6.118), pot2(sub(S, 0.733), add(2.514, sub(2.874, S)), sub(sub(add(S, S), pot2(7.318, sub(S, 0.733), S)), sub(add(S, S), pot2(7.318, 2.308, Re)))))), sub(S, 4.110))))), 0.105), pot2(sub(S, 0.733), sub(3.846, 2.098), sub(add(sub(S, -0.986), pot2(7.318, 2.308, S)), add(div(Re, Re), sub(S, -0.986)))))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Calcular métricas\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_pred)\n\u001b[0;32m     31\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, y_pred)\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[1;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    116\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "model = SymbolicRegressor(population_size=5000,\n",
    "                        generations=20, \n",
    "                        stopping_criteria=0.01,\n",
    "                        p_crossover=0.7, \n",
    "                        p_subtree_mutation=0.1,\n",
    "                        p_hoist_mutation=0.05, \n",
    "                        p_point_mutation=0.1,\n",
    "                        max_samples=0.9, \n",
    "                        verbose=1,\n",
    "                        parsimony_coefficient=0.001,\n",
    "                        const_range= (-1.0,8.0),\n",
    "                        random_state=0,\n",
    "                        function_set=['add', 'sub', 'mul', 'div',pot_fn, pot2_fn],\n",
    "                        metric = logcosh, \n",
    "                        feature_names=['S', 'Re'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la expresión simbólica\n",
    "expression = model._program\n",
    "print(\"Expresión:\", expression)\n",
    "\n",
    "# prediciendo con el conjunto de prueba\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R^2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MAPE:\",mape*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.12230538, 2.20442975, 2.42085352, ..., 1.52151373, 1.52192079,\n",
       "       1.43975326])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_test_ = y_test.values.flatten()\n",
    "y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15197103, -0.06984666,  0.14648858, ..., -0.15260832,\n",
       "       -0.15220641, -0.23438012])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_ - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01156984, 1.00244027, 1.01074865, ..., 1.01166727, 1.01160578,\n",
       "       1.02759299])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cosh(y_test_ - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08733156, 0.02263442, 0.08237704, ..., 0.08791098, 0.08754549,\n",
       "       0.16598206])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.cosh(10*(y_test_ - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_test_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "np.sum(np.log(math.cosh((y_pred - y_test_))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
